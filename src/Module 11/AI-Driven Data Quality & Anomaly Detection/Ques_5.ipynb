{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Deduplication using Clustering\n",
    "**Objective**: Learn and implement data deduplication techniques.\n",
    "\n",
    "**Task**: Hierarchical Clustering for Deduplication\n",
    "\n",
    "**Steps**:\n",
    "1. Data Set: Obtain a dataset containing duplicate employee information.\n",
    "2. Perform Clustering: Use hierarchical agglomerative clustering to cluster the employee\n",
    "records.\n",
    "3. Evaluate Duplicates: Determine duplicates by analyzing the clusters formed.\n",
    "4. Clean Data: Remove duplicate employee records found during clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with Potential Duplicates:\n",
      "   EmployeeID        Name  Age  Salary Department\n",
      "0           1  Employee 1   50   70535  Marketing\n",
      "1           2  Employee 2   36  118603      Sales\n",
      "2           3  Employee 3   29   92256      Sales\n",
      "3           4  Employee 4   42   75222  Marketing\n",
      "4           5  Employee 5   40  117373      Sales\n",
      "\n",
      "DataFrame with Cluster Assignments:\n",
      "   EmployeeID        Name  Age  Salary Department  Cluster\n",
      "0           1  Employee 1   50   70535  Marketing        8\n",
      "1           2  Employee 2   36  118603      Sales        7\n",
      "2           3  Employee 3   29   92256      Sales        3\n",
      "3           4  Employee 4   42   75222  Marketing        9\n",
      "4           5  Employee 5   40  117373      Sales        7\n",
      "\n",
      "Potential Duplicates Identified within Clusters:\n",
      "   EmployeeID        Name  Age  Salary Department  Cluster\n",
      "0           1  Employee 1   50   70535  Marketing        8\n",
      "1           2  Employee 2   36  118603      Sales        7\n",
      "2           3  Employee 3   29   92256      Sales        3\n",
      "3           4  Employee 4   42   75222  Marketing        9\n",
      "4           5  Employee 5   40  117373      Sales        7\n",
      "\n",
      "Deduplicated DataFrame:\n",
      "   EmployeeID        Name  Age  Salary Department  Cluster\n",
      "0           1  Employee 1   50   70535  Marketing        8\n",
      "1           2  Employee 2   36  118603      Sales        7\n",
      "2           3  Employee 3   29   92256      Sales        3\n",
      "3           4  Employee 4   42   75222  Marketing        9\n",
      "4           5  Employee 5   40  117373      Sales        7\n",
      "\n",
      "Number of original records: 84\n",
      "Number of deduplicated records: 84\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Generate a dataset containing duplicate employee information (replace with your actual data)\n",
    "np.random.seed(42)\n",
    "num_records = 80\n",
    "data = {\n",
    "    'EmployeeID': np.arange(1, num_records + 1),\n",
    "    'Name': [f'Employee {i}' for i in range(1, num_records + 1)],\n",
    "    'Age': np.random.randint(22, 55, num_records),\n",
    "    'Salary': np.random.randint(40000, 120000, num_records),\n",
    "    'Department': np.random.choice(['HR', 'Engineering', 'Sales', 'Marketing'], num_records)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Introduce some duplicates with slight variations\n",
    "df_duplicates = pd.DataFrame({\n",
    "    'EmployeeID': [81, 82, 83, 84],\n",
    "    'Name': ['Employee 12', 'Employe 25', 'Employee 48', 'Employee 61'], # Slight typos\n",
    "    'Age': [30, 41, 28, 49],\n",
    "    'Salary': [75000, 92000, 68000, 110000],\n",
    "    'Department': ['HR', 'Engineering', 'Sales', 'Marketing']\n",
    "})\n",
    "\n",
    "df = pd.concat([df, df_duplicates], ignore_index=True)\n",
    "np.random.shuffle(df.values) # Shuffle the order\n",
    "\n",
    "print(\"Original DataFrame with Potential Duplicates:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Perform Clustering: Use hierarchical agglomerative clustering to cluster the employee records.\n",
    "# Select numerical features for clustering\n",
    "numerical_features = ['Age', 'Salary']\n",
    "X = df[numerical_features].copy()\n",
    "\n",
    "# Standardize the numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=numerical_features)\n",
    "\n",
    "# Perform hierarchical clustering\n",
    "# Choose the number of clusters or a distance threshold\n",
    "n_clusters = 10 # You might need to determine this based on a dendrogram or domain knowledge\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward') # 'ward' minimizes variance within clusters\n",
    "df['Cluster'] = agg_clustering.fit_predict(X_scaled_df)\n",
    "\n",
    "print(\"\\nDataFrame with Cluster Assignments:\")\n",
    "print(df.head())\n",
    "\n",
    "# Optional: Visualize the dendrogram to help determine the number of clusters\n",
    "# linked = linkage(X_scaled, 'ward')\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# dendrogram(linked, orientation='top')\n",
    "# plt.title('Hierarchical Clustering Dendrogram')\n",
    "# plt.xlabel('Employee Records')\n",
    "# plt.ylabel('Distance')\n",
    "# plt.show()\n",
    "\n",
    "# Step 3: Evaluate Duplicates: Determine duplicates by analyzing the clusters formed.\n",
    "def identify_duplicates_hierarchical(cluster_df):\n",
    "    if len(cluster_df) <= 1:\n",
    "        return cluster_df\n",
    "    # Calculate pairwise distances based on the scaled numerical features\n",
    "    numerical_cols = ['Age', 'Salary']\n",
    "    distances = pairwise_distances(cluster_df[numerical_cols], metric='euclidean')\n",
    "    # Set a threshold for considering records as duplicates (you might need to tune this)\n",
    "    similarity_threshold = 1.5\n",
    "    duplicates_to_drop = set()\n",
    "    for i in range(len(cluster_df)):\n",
    "        for j in range(i + 1, len(cluster_df)):\n",
    "            if distances[i, j] < similarity_threshold:\n",
    "                # Keep the record with the lower EmployeeID as the representative\n",
    "                index_to_drop = cluster_df.iloc[j].name\n",
    "                duplicates_to_drop.add(index_to_drop)\n",
    "    return cluster_df.drop(index=duplicates_to_drop)\n",
    "\n",
    "# Group by cluster and apply the duplicate identification function\n",
    "df_potential_duplicates = df.groupby('Cluster', group_keys=False).apply(identify_duplicates_hierarchical).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nPotential Duplicates Identified within Clusters:\")\n",
    "print(df_potential_duplicates.head())\n",
    "\n",
    "# Step 4: Clean Data: Remove duplicate employee records found during clustering.\n",
    "# We can consider the records in df_potential_duplicates as the unique records\n",
    "df_deduplicated = df.loc[df_potential_duplicates.index].reset_index(drop=True)\n",
    "\n",
    "print(\"\\nDeduplicated DataFrame:\")\n",
    "print(df_deduplicated.head())\n",
    "print(f\"\\nNumber of original records: {len(df)}\")\n",
    "print(f\"Number of deduplicated records: {len(df_deduplicated.drop_duplicates(subset=['Name', 'Age', 'Salary', 'Department']))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

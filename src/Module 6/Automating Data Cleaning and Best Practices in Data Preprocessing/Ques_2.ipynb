{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Complete Pipeline for a Dataset\n",
    "1. Objective: Build a complex pipeline with multiple transformations.\n",
    "2. Steps:\n",
    "    - Load a sample dataset.\n",
    "    - Define a transformation pipeline with both imputation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with missing values:\n",
      "   feature1  feature2  feature3 category\n",
      "0      10.0       5.0       1.0        A\n",
      "1       NaN      15.0       2.0        B\n",
      "2      30.0       NaN       1.5        A\n",
      "3      40.0      35.0       2.5        C\n",
      "4      50.0      45.0       NaN        B\n",
      "\n",
      "DataFrame after imputation and scaling:\n",
      "   feature1  feature2  feature3 category\n",
      "0 -1.700840 -1.414214      -1.5        A\n",
      "1  0.000000 -0.707107       0.5        B\n",
      "2 -0.188982  0.000000      -0.5        A\n",
      "3  0.566947  0.707107       1.5        C\n",
      "4  1.322876  1.414214       0.0        B\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load a sample dataset\n",
    "data = {'feature1': [10, np.nan, 30, 40, 50],\n",
    "        'feature2': [5, 15, np.nan, 35, 45],\n",
    "        'feature3': [1.0, 2.0, 1.5, 2.5, np.nan],\n",
    "        'category': ['A', 'B', 'A', 'C', 'B']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame with missing values:\")\n",
    "print(df)\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = ['feature1', 'feature2', 'feature3']\n",
    "categorical_features = ['category']\n",
    "\n",
    "# 2. Define a transformation pipeline with both imputation and scaling\n",
    "\n",
    "# Pipeline for numerical features: Impute missing values with the mean, then scale\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For categorical features, we'll just impute missing values with the most frequent\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Apply the numerical pipeline to the numerical features\n",
    "df[numerical_features] = numerical_pipeline.fit_transform(df[numerical_features])\n",
    "\n",
    "# Apply the categorical pipeline to the categorical features\n",
    "df[categorical_features] = categorical_pipeline.fit_transform(df[categorical_features])\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(\"\\nDataFrame after imputation and scaling:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Imputation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scaling Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combined Transformation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    Age   Income       City Education  Score\n",
      "0  25.0  50000.0  Bangalore  Bachelor   0.80\n",
      "1  30.0      NaN     Mumbai    Master   0.90\n",
      "2   NaN  60000.0  Bangalore  Bachelor   0.75\n",
      "3  40.0  75000.0        NaN       PhD   0.95\n",
      "4  35.0  55000.0    Chennai    Master   0.85\n",
      "\n",
      "--- Imputation Function ---\n",
      "  num__Age num__Income num__Score  cat__City cat__Education\n",
      "0     25.0     50000.0        0.8  Bangalore       Bachelor\n",
      "1     30.0     60000.0        0.9     Mumbai         Master\n",
      "2     32.5     60000.0       0.75  Bangalore       Bachelor\n",
      "3     40.0     75000.0       0.95  Bangalore            PhD\n",
      "4     35.0     55000.0       0.85    Chennai         Master\n",
      "\n",
      "--- Scaling Function (StandardScaler) ---\n",
      "        Age    Income       City Education     Score\n",
      "0 -1.341641 -1.069045  Bangalore  Bachelor -0.707107\n",
      "1 -0.447214       NaN     Mumbai    Master  0.707107\n",
      "2       NaN  0.000000  Bangalore  Bachelor -1.414214\n",
      "3  1.341641  1.603567        NaN       PhD  1.414214\n",
      "4  0.447214 -0.534522    Chennai    Master  0.000000\n",
      "\n",
      "--- Scaling Function (MinMaxScaler) ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 167\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_scaled_standard)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Scaling Function (MinMaxScaler) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 167\u001b[0m df_scaled_minmax \u001b[38;5;241m=\u001b[39m \u001b[43mscale_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mminmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_scaled_minmax)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Combined Transformation Function (StandardScaler, One-Hot Encoding) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 76\u001b[0m, in \u001b[0;36mscale_features\u001b[0;34m(df, numerical_cols, scaler_type)\u001b[0m\n\u001b[1;32m     74\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scaler_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminmax\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m \u001b[43mMinMaxScaler\u001b[49m()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid scaler_type. Choose \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstandard\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminmax\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def impute_missing_values(df, numerical_cols=None, categorical_cols=None, numerical_strategy='mean', categorical_strategy='most_frequent'):\n",
    "    \"\"\"\n",
    "    Imputes missing values in a pandas DataFrame for specified numerical and categorical columns\n",
    "    using different strategies.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        numerical_cols (list, optional): List of numerical column names. Defaults to None (imputes all numerical columns).\n",
    "        categorical_cols (list, optional): List of categorical column names. Defaults to None (imputes all object dtype columns).\n",
    "        numerical_strategy (str, optional): Imputation strategy for numerical columns ('mean', 'median', 'constant'). Defaults to 'mean'.\n",
    "        categorical_strategy (str, optional): Imputation strategy for categorical columns ('most_frequent', 'constant'). Defaults to 'most_frequent'.\n",
    "        fill_value_numerical (float or int, optional): Value to fill missing numerical data when strategy is 'constant'. Defaults to None.\n",
    "        fill_value_categorical (object, optional): Value to fill missing categorical data when strategy is 'constant'. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    transformers = []\n",
    "\n",
    "    if numerical_cols is None:\n",
    "        numerical_cols = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    if numerical_cols:\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy=numerical_strategy))\n",
    "        ])\n",
    "        transformers.append(('num', numerical_transformer, numerical_cols))\n",
    "\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if categorical_cols:\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy=categorical_strategy))\n",
    "        ])\n",
    "        transformers.append(('cat', categorical_transformer, categorical_cols))\n",
    "\n",
    "    if not transformers:\n",
    "        print(\"No numerical or categorical columns specified or found.\")\n",
    "        return df_copy\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "    df_imputed = pd.DataFrame(preprocessor.fit_transform(df_copy), columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "def scale_features(df, numerical_cols=None, scaler_type='standard'):\n",
    "    \"\"\"\n",
    "    Scales numerical features in a pandas DataFrame using either StandardScaler or MinMaxScaler.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        numerical_cols (list, optional): List of numerical column names to scale. Defaults to None (scales all numerical columns).\n",
    "        scaler_type (str, optional): Type of scaler to use ('standard' for StandardScaler, 'minmax' for MinMaxScaler). Defaults to 'standard'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the specified numerical features scaled.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if numerical_cols is None:\n",
    "        numerical_cols = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "    if not numerical_cols:\n",
    "        print(\"No numerical columns specified or found to scale.\")\n",
    "        return df_copy\n",
    "\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaler_type. Choose 'standard' or 'minmax'.\")\n",
    "\n",
    "    df_copy[numerical_cols] = scaler.fit_transform(df_copy[numerical_cols])\n",
    "    return df_copy\n",
    "\n",
    "def combined_transformation(df, numerical_cols=None, categorical_cols=None,\n",
    "                            numerical_imputer_strategy='mean', categorical_imputer_strategy='most_frequent',\n",
    "                            scaler_type='standard', encoder_type='onehot'):\n",
    "    \"\"\"\n",
    "    Performs imputation, scaling (for numerical), and encoding (for categorical) on a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        numerical_cols (list, optional): List of numerical column names. Defaults to None (uses all numerical columns).\n",
    "        categorical_cols (list, optional): List of categorical column names. Defaults to None (uses all object/category columns).\n",
    "        numerical_imputer_strategy (str, optional): Imputation strategy for numerical columns. Defaults to 'mean'.\n",
    "        categorical_imputer_strategy (str, optional): Imputation strategy for categorical columns. Defaults to 'most_frequent'.\n",
    "        scaler_type (str, optional): Type of scaler for numerical columns ('standard', 'minmax'). Defaults to 'standard'.\n",
    "        encoder_type (str, optional): Type of encoder for categorical columns ('onehot', 'label'). Defaults to 'onehot'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The transformed DataFrame.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    transformers = []\n",
    "\n",
    "    if numerical_cols is None:\n",
    "        numerical_cols = df_copy.select_dtypes(include=['number']).columns.tolist()\n",
    "    if numerical_cols:\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy=numerical_imputer_strategy)),\n",
    "            ('scaler', StandardScaler() if scaler_type == 'standard' else MinMaxScaler())\n",
    "        ])\n",
    "        transformers.append(('num', numerical_transformer, numerical_cols))\n",
    "\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = df_copy.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if categorical_cols:\n",
    "        if encoder_type == 'onehot':\n",
    "            categorical_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=categorical_imputer_strategy)),\n",
    "                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "            ])\n",
    "        elif encoder_type == 'label':\n",
    "            # LabelEncoder works on one column at a time, so we'll handle it differently\n",
    "            df_encoded_categorical = df_copy[categorical_cols].copy()\n",
    "            for col in categorical_cols:\n",
    "                label_encoder = LabelEncoder()\n",
    "                df_encoded_categorical[col] = label_encoder.fit_transform(df_encoded_categorical[col].astype(str)) # Handle potential NaNs\n",
    "            # We'll return the concatenated DataFrame later\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Invalid encoder_type. Choose 'onehot' or 'label'.\")\n",
    "\n",
    "        if encoder_type == 'onehot':\n",
    "            transformers.append(('cat', categorical_transformer, categorical_cols))\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "    df_transformed = pd.DataFrame(preprocessor.fit_transform(df_copy), columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "    if encoder_type == 'label' and categorical_cols:\n",
    "        # Drop original categorical columns and concatenate the label encoded ones\n",
    "        df_transformed = df_transformed.drop(columns=categorical_cols, errors='ignore')\n",
    "        df_transformed = pd.concat([df_transformed, df_encoded_categorical.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return df_transformed\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create a sample DataFrame\n",
    "    data = {'Age': [25, 30, np.nan, 40, 35],\n",
    "            'Income': [50000, np.nan, 60000, 75000, 55000],\n",
    "            'City': ['Bangalore', 'Mumbai', 'Bangalore', np.nan, 'Chennai'],\n",
    "            'Education': ['Bachelor', 'Master', 'Bachelor', 'PhD', 'Master'],\n",
    "            'Score': [0.8, 0.9, 0.75, 0.95, 0.85]}\n",
    "    sample_df = pd.DataFrame(data)\n",
    "    print(\"Original DataFrame:\")\n",
    "    print(sample_df)\n",
    "\n",
    "    print(\"\\n--- Imputation Function ---\")\n",
    "    df_imputed = impute_missing_values(sample_df)\n",
    "    print(df_imputed)\n",
    "\n",
    "    print(\"\\n--- Scaling Function (StandardScaler) ---\")\n",
    "    df_scaled_standard = scale_features(sample_df.copy(), scaler_type='standard')\n",
    "    print(df_scaled_standard)\n",
    "\n",
    "    print(\"\\n--- Scaling Function (MinMaxScaler) ---\")\n",
    "    df_scaled_minmax = scale_features(sample_df.copy(), scaler_type='minmax')\n",
    "    print(df_scaled_minmax)\n",
    "\n",
    "    print(\"\\n--- Combined Transformation Function (StandardScaler, One-Hot Encoding) ---\")\n",
    "    df_transformed_onehot = combined_transformation(sample_df.copy(), scaler_type='standard', encoder_type='onehot')\n",
    "    print(df_transformed_onehot)\n",
    "\n",
    "    print(\"\\n--- Combined Transformation Function (MinMaxScaler, Label Encoding) ---\")\n",
    "    df_transformed_label = combined_transformation(sample_df.copy(), scaler_type='minmax', encoder_type='label')\n",
    "    print(df_transformed_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

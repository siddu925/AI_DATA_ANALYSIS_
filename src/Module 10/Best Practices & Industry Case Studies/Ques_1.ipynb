{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Data Quality SLAs\n",
    "### Data Completeness\n",
    "**Description**: Set an SLA that ensures that 95% of data fields in your dataset are filled (non-null values). Practice by checking a dataset of your choice and calculate its completeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File not found at data_completeness_check.csv\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations' has no attribute 'DataContext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     exit()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 2. Create a Great Expectations Data Context (if you don't have one)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mgx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataContext\u001b[49m()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 3. Add a Pandas DataFrame Data Source and Data Asset\u001b[39;00m\n\u001b[1;32m     16\u001b[0m datasource_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleteness_data_source\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations' has no attribute 'DataContext'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load your dataset using Pandas\n",
    "csv_file_path = \"data_completeness_check.csv\"  # Replace with the path to your dataset\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at {csv_file_path}\")\n",
    "    exit()\n",
    "\n",
    "# 2. Create a Great Expectations Data Context (if you don't have one)\n",
    "context = gx.DataContext()\n",
    "\n",
    "# 3. Add a Pandas DataFrame Data Source and Data Asset\n",
    "datasource_name = \"completeness_data_source\"\n",
    "datasource = context.sources.add_pandas(name=datasource_name)\n",
    "\n",
    "data_asset_name = \"completeness_data\"\n",
    "data_asset = datasource.add_dataframe_asset(name=data_asset_name)\n",
    "\n",
    "batch_request = data_asset.build_batch_request(dataframe=df)\n",
    "\n",
    "# 4. Get a Validator\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=\"data_completeness_suite\",  # You can name your suite\n",
    ")\n",
    "\n",
    "print(f\"Using Expectation Suite: {validator.expectation_suite.name}\")\n",
    "\n",
    "# 5. Define the expectation for data completeness (at least 95% non-null values)\n",
    "completeness_threshold = 0.95\n",
    "\n",
    "# We'll use expect_column_values_to_not_be_null for each column\n",
    "for column in df.columns:\n",
    "    validator.expect_column_values_to_not_be_null(\n",
    "        column=column,\n",
    "        mostly=completeness_threshold,\n",
    "    )\n",
    "\n",
    "# 6. Save the Expectation Suite\n",
    "validator.save_expectation_suite()\n",
    "\n",
    "# 7. Run the validation using a Checkpoint\n",
    "checkpoint_name = \"data_completeness_checkpoint\"\n",
    "checkpoint_result = context.run_checkpoint(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    validations=[\n",
    "        {\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": \"data_completeness_suite\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 8. Review the validation results to see if the SLA is met\n",
    "print(\"\\nValidation Results against SLA (95% completeness per field):\")\n",
    "validation_result = checkpoint_result.list_validation_results()[0]\n",
    "sla_met = True\n",
    "for expectation_result in validation_result[\"results\"]:\n",
    "    if expectation_result[\"expectation_config\"][\"expectation_type\"] == \"expect_column_values_to_not_be_null\":\n",
    "        column_name = expectation_result[\"expectation_config\"][\"kwargs\"][\"column\"]\n",
    "        success = expectation_result[\"success\"]\n",
    "        mostly = expectation_result[\"expectation_config\"][\"kwargs\"].get(\"mostly\", 1.0)\n",
    "        print(f\"Column '{column_name}': SLA Met = {success} (Expected >= {mostly*100:.2f}%)\")\n",
    "        if not success:\n",
    "            sla_met = False\n",
    "\n",
    "if sla_met:\n",
    "    print(\"\\nData Completeness SLA (95% non-null per field) was MET for all fields.\")\n",
    "else:\n",
    "    print(\"\\nData Completeness SLA (95% non-null per field) was NOT MET for one or more fields.\")\n",
    "\n",
    "# 9. Calculate and print the overall data completeness\n",
    "total_cells = df.size\n",
    "non_null_cells = df.count().sum()\n",
    "overall_completeness = (non_null_cells / total_cells) if total_cells > 0 else 0.0\n",
    "print(f\"\\nOverall Data Completeness: {overall_completeness * 100:.2f}%\")\n",
    "\n",
    "# 10. Optionally, view the detailed report in Data Docs\n",
    "print(\"\\nTo view the detailed validation report in Data Docs:\")\n",
    "print(f\"- Navigate to your Great Expectations Data Context directory.\")\n",
    "print(\"- Run the command: `great_expectations docs build`\")\n",
    "print(\"- Open the generated `index.html` file and find the results for the '{checkpoint_name}' Checkpoint and the 'data_completeness_suite' Expectation Suite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Timeliness:\n",
    "**Description**: Establish an SLA that specifies that data should be integrated and processed within 24 hours of acquisition. Monitor the data pipeline for timeliness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'great_expectations' has no attribute 'DataContext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m sla_threshold \u001b[38;5;241m=\u001b[39m timedelta(hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 2. Create a Great Expectations Data Context\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[43mgx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataContext\u001b[49m()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 3. Add a Pandas DataFrame Data Source and Data Asset\u001b[39;00m\n\u001b[1;32m     28\u001b[0m datasource_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_metadata_source\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'great_expectations' has no attribute 'DataContext'"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 1. Simulate fetching pipeline metadata (replace with your actual metadata retrieval)\n",
    "pipeline_metadata = [\n",
    "    {\"data_id\": \"batch_1\", \"acquisition_time\": \"2025-05-15 10:00:00\", \"processing_end_time\": \"2025-05-15 18:00:00\"},\n",
    "    {\"data_id\": \"batch_2\", \"acquisition_time\": \"2025-05-15 12:30:00\", \"processing_end_time\": \"2025-05-16 11:00:00\"},\n",
    "    {\"data_id\": \"batch_3\", \"acquisition_time\": \"2025-05-16 09:00:00\", \"processing_end_time\": \"2025-05-17 10:00:00\"},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(pipeline_metadata)\n",
    "\n",
    "# Convert timestamp strings to datetime objects\n",
    "df['acquisition_time'] = pd.to_datetime(df['acquisition_time'])\n",
    "df['processing_end_time'] = pd.to_datetime(df['processing_end_time'])\n",
    "\n",
    "# Calculate the processing duration\n",
    "df['processing_duration'] = df['processing_end_time'] - df['acquisition_time']\n",
    "\n",
    "# Define the SLA threshold (24 hours)\n",
    "sla_threshold = timedelta(hours=24)\n",
    "\n",
    "# 2. Create a Great Expectations Data Context\n",
    "context = gx.DataContext()\n",
    "\n",
    "# 3. Add a Pandas DataFrame Data Source and Data Asset\n",
    "datasource_name = \"pipeline_metadata_source\"\n",
    "datasource = context.sources.add_pandas(name=datasource_name)\n",
    "\n",
    "data_asset_name = \"pipeline_runs\"\n",
    "data_asset = datasource.add_dataframe_asset(name=data_asset_name)\n",
    "\n",
    "batch_request = data_asset.build_batch_request(dataframe=df)\n",
    "\n",
    "# 4. Get a Validator\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=\"data_timeliness_suite\",\n",
    ")\n",
    "\n",
    "print(f\"Using Expectation Suite: {validator.expectation_suite.name}\")\n",
    "\n",
    "# 5. Define the expectation to check if processing duration is within the SLA\n",
    "validator.expect_column_values_to_be_less_than_or_equal_to(\n",
    "    column=\"processing_duration\",\n",
    "    value=sla_threshold,\n",
    "    mostly=1.0,  # Expect all batches to meet the SLA\n",
    ")\n",
    "\n",
    "# 6. Save the Expectation Suite\n",
    "validator.save_expectation_suite()\n",
    "\n",
    "# 7. Run the validation using a Checkpoint\n",
    "checkpoint_name = \"data_timeliness_checkpoint\"\n",
    "checkpoint_result = context.run_checkpoint(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    validations=[\n",
    "        {\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": \"data_timeliness_suite\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 8. Review the validation results\n",
    "print(\"\\nValidation Results for Data Timeliness SLA (<= 24 hours):\")\n",
    "validation_result = checkpoint_result.list_validation_results()[0]\n",
    "timeliness_sla_met = True\n",
    "for expectation_result in validation_result[\"results\"]:\n",
    "    if expectation_result[\"expectation_config\"][\"expectation_type\"] == \"expect_column_values_to_be_less_than_or_equal_to\" and expectation_result[\"expectation_config\"][\"kwargs\"][\"column\"] == \"processing_duration\":\n",
    "        success = expectation_result[\"success\"]\n",
    "        print(f\"Timeliness SLA Met for all batches: {success}\")\n",
    "        if not success:\n",
    "            timeliness_sla_met = False\n",
    "            if \"partial_unexpected_list\" in expectation_result[\"result\"]:\n",
    "                print(f\"  - Batches exceeding SLA: {expectation_result['result']['partial_unexpected_list']}\")\n",
    "\n",
    "if timeliness_sla_met:\n",
    "    print(\"\\nData Timeliness SLA (processing within 24 hours) was MET for all monitored batches.\")\n",
    "else:\n",
    "    print(\"\\nData Timeliness SLA (processing within 24 hours) was NOT MET for one or more monitored batches.\")\n",
    "\n",
    "# 9. Optionally, view the detailed report in Data Docs\n",
    "print(\"\\nTo view the detailed validation report in Data Docs:\")\n",
    "print(f\"- Navigate to your Great Expectations Data Context directory.\")\n",
    "print(\"- Run the command: `great_expectations docs build`\")\n",
    "print(\"- Open the generated `index.html` file and find the results for the '{checkpoint_name}' Checkpoint and the 'data_timeliness_suite' Expectation Suite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Consistency:\n",
    "**Description**: Define an SLA for maintaining consistency across various related datasets. Implement a check to ensure that 99% of data entries are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Simulate two related datasets (replace with your actual data loading)\n",
    "data1 = [\n",
    "    {\"CustomerID\": 1, \"ProductName\": \"Laptop\", \"OrderDate\": \"2025-05-10\", \"Status_A\": \"Shipped\"},\n",
    "    {\"CustomerID\": 2, \"ProductName\": \"Mouse\", \"OrderDate\": \"2025-05-11\", \"Status_A\": \"Delivered\"},\n",
    "    {\"CustomerID\": 3, \"ProductName\": \"Keyboard\", \"OrderDate\": \"2025-05-12\", \"Status_A\": \"Shipped\"},\n",
    "    {\"CustomerID\": 4, \"ProductName\": \"Monitor\", \"OrderDate\": \"2025-05-13\", \"Status_A\": \"Pending\"},\n",
    "    {\"CustomerID\": 5, \"ProductName\": \"Webcam\", \"OrderDate\": \"2025-05-14\", \"Status_A\": \"Shipped\"},\n",
    "]\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "data2 = [\n",
    "    {\"CustomerID\": 1, \"Product\": \"Laptop\", \"DeliveryDate\": \"2025-05-12\", \"Status_B\": \"Shipped\"},\n",
    "    {\"CustomerID\": 2, \"Product\": \"Mouse\", \"DeliveryDate\": \"2025-05-13\", \"Status_B\": \"Delivered\"},\n",
    "    {\"CustomerID\": 3, \"Product\": \"Keyboard\", \"DeliveryDate\": \"2025-05-12\", \"Status_B\": \"Processing\"},\n",
    "    {\"CustomerID\": 4, \"Product\": \"Monitor\", \"DeliveryDate\": \"2025-05-14\", \"Status_B\": \"Pending\"},\n",
    "    {\"CustomerID\": 6, \"Product\": \"Tablet\", \"DeliveryDate\": \"2025-05-15\", \"Status_B\": \"Shipped\"},\n",
    "]\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# 2. Create a Great Expectations Data Context\n",
    "context = gx.DataContext()\n",
    "\n",
    "# 3. Add Pandas DataFrame Data Sources and Data Assets for both DataFrames\n",
    "datasource_name = \"consistency_data_source\"\n",
    "datasource = context.sources.add_pandas(name=datasource_name)\n",
    "\n",
    "data_asset_name_1 = \"dataset_1\"\n",
    "data_asset_1 = datasource.add_dataframe_asset(name=data_asset_name_1)\n",
    "batch_request_1 = data_asset_1.build_batch_request(dataframe=df1)\n",
    "\n",
    "data_asset_name_2 = \"dataset_2\"\n",
    "data_asset_2 = datasource.add_dataframe_asset(name=data_asset_name_2)\n",
    "batch_request_2 = data_asset_2.build_batch_request(dataframe=df2)\n",
    "\n",
    "# 4. Get Validators for both Data Assets\n",
    "validator_1 = context.get_validator(\n",
    "    batch_request=batch_request_1,\n",
    "    expectation_suite_name=\"consistency_suite_dataset_1\",  # You can have separate suites or one\n",
    ")\n",
    "\n",
    "validator_2 = context.get_validator(\n",
    "    batch_request=batch_request_2,\n",
    "    expectation_suite_name=\"consistency_suite_dataset_2\",\n",
    ")\n",
    "\n",
    "print(f\"Using Expectation Suite 1: {validator_1.expectation_suite.name}\")\n",
    "print(f\"Using Expectation Suite 2: {validator_2.expectation_suite.name}\")\n",
    "\n",
    "# 5. Implement checks for consistency (example: status consistency where CustomerID exists in both)\n",
    "merged_df = pd.merge(df1, df2, on=\"CustomerID\", how=\"inner\", suffixes=(\"_A\", \"_B\"))\n",
    "\n",
    "if not merged_df.empty:\n",
    "    consistency_threshold = 0.99\n",
    "    consistent_status_count = (merged_df[\"Status_A\"] == merged_df[\"Status_B\"]).sum()\n",
    "    total_common_records = len(merged_df)\n",
    "    consistency_rate = consistent_status_count / total_common_records if total_common_records > 0 else 1.0\n",
    "\n",
    "    print(f\"\\nConsistency Check for 'Status' across common CustomerIDs:\")\n",
    "    print(f\"Consistent Status Count: {consistent_status_count}\")\n",
    "    print(f\"Total Common Records: {total_common_records}\")\n",
    "    print(f\"Consistency Rate: {consistency_rate * 100:.2f}%\")\n",
    "\n",
    "    # You could add an expectation here on the calculated consistency rate\n",
    "    validator_1.expect_value_to_be_greater_than_or_equal_to(\n",
    "        value=consistency_rate,\n",
    "        mostly=1.0 - (1.0 - consistency_threshold),  # Allow for the inverse of the inconsistency rate\n",
    "        expectation_type=\"custom_status_consistency\",  # Custom expectation type for reporting\n",
    "        meta={\"notes\": f\"SLA for status consistency: >= {consistency_threshold * 100:.2f}%\"},\n",
    "    )\n",
    "    validator_1.save_expectation_suite()\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo common CustomerIDs found between the datasets to check status consistency.\")\n",
    "\n",
    "# 6. You might also want to check for the presence of keys across datasets\n",
    "# Example: Ensure all CustomerIDs in df1 also exist in df2 (or vice-versa, or a significant percentage)\n",
    "customer_ids_1 = set(df1[\"CustomerID\"])\n",
    "customer_ids_2 = set(df2[\"CustomerID\"])\n",
    "\n",
    "present_in_1_not_in_2 = customer_ids_1 - customer_ids_2\n",
    "present_in_2_not_in_1 = customer_ids_2 - customer_ids_1\n",
    "\n",
    "print(f\"\\nCustomer IDs present only in Dataset 1: {present_in_1_not_in_2}\")\n",
    "print(f\"Customer IDs present only in Dataset 2: {present_in_2_not_in_1}\")\n",
    "\n",
    "# You could add expectations here to check for the acceptable number of missing keys\n",
    "validator_1.expect_column_values_to_be_in_set(\n",
    "    column=\"CustomerID\",\n",
    "    value_set=list(customer_ids_2),\n",
    "    mostly=0.99,  # Expect at least 99% of CustomerIDs from df1 to be in df2\n",
    "    expectation_type=\"customer_id_overlap_1_to_2\",\n",
    "    meta={\"notes\": \"SLA: At least 99% of CustomerIDs from Dataset 1 should be in Dataset 2\"},\n",
    ")\n",
    "validator_1.save_expectation_suite()\n",
    "\n",
    "# 7. Run validation (using validator_1 as it contains the consistency checks)\n",
    "checkpoint_name = \"data_consistency_checkpoint\"\n",
    "checkpoint_result = context.run_checkpoint(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    validations=[\n",
    "        {\n",
    "            \"batch_request\": batch_request_1,\n",
    "            \"expectation_suite_name\": \"consistency_suite_dataset_1\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 8. Review the validation results\n",
    "print(\"\\nValidation Results for Data Consistency:\")\n",
    "validation_result = checkpoint_result.list_validation_results()[0]\n",
    "for expectation_result in validation_result[\"results\"]:\n",
    "    print(f\"Expectation: {expectation_result['expectation_config']['expectation_type']}, Success: {expectation_result['success']}, Details: {expectation_result['result']}\")\n",
    "\n",
    "# 9. Optionally, view the detailed report in Data Docs\n",
    "print(\"\\nTo view the detailed validation report in Data Docs:\")\n",
    "print(f\"- Navigate to your Great Expectations Data Context directory.\")\n",
    "print(\"- Run the command: `great_expectations docs build`\")\n",
    "print(\"- Open the generated `index.html` file and find the results for the '{checkpoint_name}' Checkpoint and the 'consistency_suite_dataset_1' Expectation Suite.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

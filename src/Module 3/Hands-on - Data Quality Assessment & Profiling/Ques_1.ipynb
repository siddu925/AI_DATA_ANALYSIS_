{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load a CSV Dataset\n",
    "# Description: Load a CSV file into a Pandas DataFrame and print the first five rows to understand the structure of the dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Print the first five rows of the DataFrame\n",
    "    print(\"First five rows of the dataset:\")\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Check for Missing Values\n",
    "# Description: Identify and list the columns with missing values and the number of missing values in each.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Check for missing values in each column\n",
    "    missing_values = df.isnull().sum()\n",
    "\n",
    "    # Filter out columns with no missing values\n",
    "    columns_with_missing = missing_values[missing_values > 0]\n",
    "\n",
    "    # Print the columns with missing values and their counts\n",
    "    if not columns_with_missing.empty:\n",
    "        print(\"Columns with missing values:\")\n",
    "        print(columns_with_missing)\n",
    "    else:\n",
    "        print(\"No missing values found in the dataset.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Visualize Missing Data\n",
    "# Description: Use a heatmap to visualize the missing values in the dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Create a heatmap of missing values\n",
    "    plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "    plt.title('Missing Values Heatmap')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.ylabel('Rows')\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Remove Columns with Many Missing Values\n",
    "# Description: Drop columns that have more than 50% missing values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate the percentage of missing values in each column\n",
    "    missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "    # Identify columns with more than 50% missing values\n",
    "    columns_to_drop = missing_percentage[missing_percentage > 50].index\n",
    "\n",
    "    # Drop the identified columns\n",
    "    df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "    print(f\"Original DataFrame shape: {df.shape}\")\n",
    "    print(f\"Number of columns dropped: {len(columns_to_drop)}\")\n",
    "    print(f\"Dropped columns: {list(columns_to_drop)}\")\n",
    "    print(f\"Cleaned DataFrame shape: {df_cleaned.shape}\")\n",
    "    print(\"\\nFirst five rows of the cleaned DataFrame:\")\n",
    "    print(df_cleaned.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Identify Duplicate Rows\n",
    "# Description: Check for and display any duplicate rows in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Identify duplicate rows\n",
    "    duplicate_rows = df[df.duplicated()]\n",
    "\n",
    "    # Check if any duplicate rows exist\n",
    "    if not duplicate_rows.empty:\n",
    "        print(\"Duplicate rows found:\")\n",
    "        print(duplicate_rows)\n",
    "        print(f\"\\nNumber of duplicate rows: {len(duplicate_rows)}\")\n",
    "    else:\n",
    "        print(\"No duplicate rows found in the dataset.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Remove Duplicate Rows\n",
    "# Description: Remove duplicate rows from the dataset and verify that they have been removed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Check for the initial number of rows\n",
    "    initial_rows = len(df)\n",
    "    print(f\"Initial number of rows: {initial_rows}\")\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "\n",
    "    # Check the number of rows after removing duplicates\n",
    "    rows_after_removal = len(df_cleaned)\n",
    "    print(f\"Number of rows after removing duplicates: {rows_after_removal}\")\n",
    "\n",
    "    # Check the number of duplicate rows removed\n",
    "    duplicates_removed = initial_rows - rows_after_removal\n",
    "    print(f\"Number of duplicate rows removed: {duplicates_removed}\")\n",
    "\n",
    "    # Verify that no duplicate rows remain\n",
    "    duplicate_rows_after_removal = df_cleaned[df_cleaned.duplicated()]\n",
    "    if duplicate_rows_after_removal.empty:\n",
    "        print(\"Verification: No duplicate rows found in the cleaned DataFrame.\")\n",
    "    else:\n",
    "        print(\"Warning: Duplicate rows still exist in the cleaned DataFrame.\")\n",
    "        print(duplicate_rows_after_removal)\n",
    "\n",
    "    # Optionally, you can overwrite the original DataFrame with the cleaned one\n",
    "    # df = df_cleaned\n",
    "\n",
    "    print(\"\\nFirst five rows of the cleaned DataFrame:\")\n",
    "    print(df_cleaned.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7: Check Data Inconsistencies\n",
    "# Description: Identify inconsistencies in categorical columns, such as differing text cases or trailing spaces.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Identify categorical columns (you might need to adjust this based on your dataset)\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    print(\"Checking for inconsistencies in categorical columns:\")\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\nColumn: {col}\")\n",
    "\n",
    "        # Check for different text cases\n",
    "        lowercase_values = df[col].str.lower().unique()\n",
    "        original_unique_values = df[col].unique()\n",
    "        case_inconsistencies = [val for val in original_unique_values if val.lower() in lowercase_values and val != val.lower()]\n",
    "        if case_inconsistencies:\n",
    "            print(f\"  Potential case inconsistencies: {case_inconsistencies}\")\n",
    "\n",
    "        # Check for trailing/leading spaces\n",
    "        stripped_values = df[col].str.strip().unique()\n",
    "        space_inconsistencies = [val for val in original_unique_values if val.strip() in stripped_values and val != val.strip()]\n",
    "        if space_inconsistencies:\n",
    "            print(f\"  Potential leading/trailing space inconsistencies: {space_inconsistencies}\")\n",
    "\n",
    "        # You can add more checks here for other types of inconsistencies,\n",
    "        # like different spellings of the same category.\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 8: Get Summary of Data Quality\n",
    "# Description: Generate a summary of data quality including total records, number of duplicate rows, and columns with missing values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 1. Total number of records\n",
    "    total_records = len(df)\n",
    "\n",
    "    # 2. Number of duplicate rows\n",
    "    duplicate_rows = df[df.duplicated()]\n",
    "    num_duplicate_rows = len(duplicate_rows)\n",
    "\n",
    "    # 3. Columns with missing values\n",
    "    missing_values = df.isnull().sum()\n",
    "    columns_with_missing = missing_values[missing_values > 0]\n",
    "\n",
    "    print(\"Data Quality Summary:\")\n",
    "    print(f\"Total number of records: {total_records}\")\n",
    "    print(f\"Number of duplicate rows: {num_duplicate_rows}\")\n",
    "\n",
    "    if not columns_with_missing.empty:\n",
    "        print(\"Columns with missing values:\")\n",
    "        print(columns_with_missing)\n",
    "    else:\n",
    "        print(\"No columns with missing values found.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 9: Generate a Data Quality Report\n",
    "# Description: Create a comprehensive data quality report that includes not only missing values but also basic statistics for numerical columns and the distribution of categorical columns.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "def generate_data_quality_report(df):\n",
    "    \"\"\"Generates a comprehensive data quality report for a Pandas DataFrame.\"\"\"\n",
    "    report = {}\n",
    "\n",
    "    # 1. Basic Information\n",
    "    report['total_records'] = len(df)\n",
    "    report['total_columns'] = df.shape[1]\n",
    "\n",
    "    # 2. Missing Values\n",
    "    missing_values = df.isnull().sum()\n",
    "    report['columns_with_missing'] = missing_values[missing_values > 0].to_dict()\n",
    "    report['total_missing_values'] = missing_values.sum()\n",
    "\n",
    "    # 3. Duplicate Rows\n",
    "    duplicate_rows = df[df.duplicated()]\n",
    "    report['num_duplicate_rows'] = len(duplicate_rows)\n",
    "\n",
    "    # 4. Numerical Column Statistics\n",
    "    numerical_cols = df.select_dtypes(include=['number'])\n",
    "    report['numerical_column_stats'] = numerical_cols.describe().to_dict()\n",
    "\n",
    "    # 5. Categorical Column Distribution\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category'])\n",
    "    report['categorical_column_distribution'] = {}\n",
    "    for col in categorical_cols:\n",
    "        report['categorical_column_distribution'][col] = df[col].value_counts().to_dict()\n",
    "\n",
    "    return report\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Generate the data quality report\n",
    "    data_quality_report = generate_data_quality_report(df)\n",
    "\n",
    "    print(\"Data Quality Report:\")\n",
    "    import json\n",
    "    print(json.dumps(data_quality_report, indent=4))\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 10: Advanced Data Imputation\n",
    "# Description: Perform advanced data imputation by replacing missing values in numerical columns with the mean and categorical columns with the mode.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'your_dataset.csv' was not found. Please make sure the file exists in the specified location.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your CSV file is named 'your_dataset.csv' and is in the same directory\n",
    "file_path = 'your_dataset.csv'\n",
    "\n",
    "try:\n",
    "    # Load the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(\"Number of missing values before imputation:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Impute missing values in numerical columns with the mean\n",
    "    for col in numerical_cols:\n",
    "        if df[col].isnull().any():\n",
    "            mean_val = df[col].mean()\n",
    "            df[col].fillna(mean_val, inplace=True)\n",
    "            print(f\"Missing values in numerical column '{col}' imputed with mean: {mean_val:.2f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # Impute missing values in categorical columns with the mode\n",
    "    for col in categorical_cols:\n",
    "        if df[col].isnull().any():\n",
    "            mode_val = df[col].mode()[0]  # mode() can return multiple values, so we take the first\n",
    "            df[col].fillna(mode_val, inplace=True)\n",
    "            print(f\"Missing values in categorical column '{col}' imputed with mode: '{mode_val}'\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"Number of missing values after imputation:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    print(\"First five rows of the DataFrame after imputation:\")\n",
    "    print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please make sure the file exists in the specified location.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the dataset: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 4: Data Quality Automation Tools\n",
    "\n",
    "# Task A: Using Great Expectations\n",
    "\n",
    "# 19. Setting Up Expectations:\n",
    "# - Install Great Expectations and set up a basic expectation suite.\n",
    "# - Validate a dataset and list unmet expectations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 20. Testing for Expectation:\n",
    "# - Create expectations such as “column values must fall within a certain range.”\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 21. Generating Data Docs:\n",
    "# - Automatically generate data quality documentation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Sample DataFrame (replace with your actual data)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_column\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023/10/26\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m26-Nov-22\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m12.05.2024\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOct 26, 2023\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20221126\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m01/05/2023\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m05/01/2024\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m45\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_column\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  mixed Case  \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mALL CAPS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProper Case\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124manother STRING\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from dateutil import parser\n",
    "\n",
    "# Sample DataFrame (replace with your actual data)\n",
    "data = {\n",
    "    'date_column': ['2023/10/26', '26-Nov-22', '12.05.2024', 'Oct 26, 2023', '20221126', '01/05/2023', '05/01/2024'],\n",
    "    'age': [30, -5, 45, 0, 22, 100, -1],\n",
    "    'email': ['test@example.com', 'invalid_email', 'another@domain.net', 'TEST@EXAMPLE.COM', 'Valid.Email@sub.domain.co.uk'],\n",
    "    'phone': ['123-456-7890', '123.456.7890', '1234567890', '(123) 456-7890', '123 456 7890', '+1-555-1212', '44 20 7946 0991'],\n",
    "    'text_column': ['  mixed Case  ', 'ALL CAPS', 'lowercase', 'Proper Case', 'another STRING']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 13. Date Format Standardization\n",
    "def standardize_date(date_str):\n",
    "    formats_to_try = ['%Y/%m/%d', '%d-%b-%y', '%d.%m.%Y', '%b %d, %Y', '%Y%m%d']\n",
    "    for fmt in formats_to_try:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format=fmt).strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            continue\n",
    "    try:\n",
    "        return parser.parse(date_str).strftime('%Y-%m-%d') # Try dateutil for more flexibility\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "df['date_standardized'] = df['date_column'].apply(standardize_date)\n",
    "print(\"13. Date Format Standardization:\")\n",
    "print(df[['date_column', 'date_standardized']])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 14. Numeric Constraints Enforcement (age > 0)\n",
    "df_cleaned_age = df[df['age'] > 0].copy() # Create a copy to avoid SettingWithCopyWarning\n",
    "df['age_valid'] = df['age'] > 0\n",
    "print(\"14. Numeric Constraints Enforcement (age > 0):\")\n",
    "print(\"Cleaned DataFrame (age > 0):\\n\", df_cleaned_age[['age']])\n",
    "print(\"\\nOriginal DataFrame with 'age_valid' flag:\\n\", df[['age', 'age_valid']])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 15. String Format Checks (basic email format)\n",
    "def is_valid_email(email):\n",
    "    pattern = r\"[^@]+@[^@]+\\.[^@]+\"\n",
    "    return bool(re.match(pattern, str(email))) # Ensure email is treated as string\n",
    "\n",
    "df['email_valid'] = df['email'].apply(is_valid_email)\n",
    "print(\"15. String Format Checks (basic email format):\")\n",
    "print(df[['email', 'email_valid']])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 16. Standardizing Date Formats (handling inconsistencies - using the same function as 13)\n",
    "print(\"16. Standardizing Date Formats (handling inconsistencies):\")\n",
    "print(df[['date_column', 'date_standardized']]) # Already done in step 13\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 17. Pattern Matching for Consistency (phone numbers to (123) 456-7890)\n",
    "def standardize_phone(phone_number):\n",
    "    digits_only = re.sub(r'\\D', '', str(phone_number)) # Ensure phone_number is a string\n",
    "    if len(digits_only) == 10:\n",
    "        return f\"({digits_only[:3]}) {digits_only[3:6]}-{digits_only[6:]}\"\n",
    "    elif digits_only.startswith('1') and len(digits_only) == 11: # Handle +1 or 1 prefix\n",
    "        return f\"({digits_only[1:4]}) {digits_only[4:7]}-{digits_only[7:]}\"\n",
    "    elif digits_only.startswith('44') and len(digits_only) == 11: # Basic UK mobile\n",
    "        return f\"0{digits_only[2:]}\" # Example UK format\n",
    "    elif digits_only.startswith('44') and len(digits_only) == 10: # Basic UK landline\n",
    "        return f\"0{digits_only[2:]}\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['phone_standardized'] = df['phone'].apply(standardize_phone)\n",
    "print(\"17. Pattern Matching for Consistency (phone numbers to (123) 456-7890):\")\n",
    "print(df[['phone', 'phone_standardized']])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 18. Handling Mixed Case Text (all uppercase)\n",
    "df['text_uppercase'] = df['text_column'].str.upper().str.strip()\n",
    "print(\"18. Handling Mixed Case Text (all uppercase):\")\n",
    "print(df[['text_column', 'text_uppercase']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task B: Using DQ Labs\n",
    "\n",
    "# 22. Tool Setup and Configuration:\n",
    "# - Download and configure DQ Labs on your local environment.\n",
    "# - Create a new data quality project.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 23. Data Analysis Automation:\n",
    "# - Apply DQ Labs for automating data profiling and quality checks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 24. Quality Rule Creation:\n",
    "# - Create quality rules for detecting and handling duplicates or enforcing standards.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas great_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "import os\n",
    "\n",
    "# 1. Create a Data Context.  This is the main configuration object for Great Expectations.\n",
    "context = ge.data_context.DataContext.create(project_dir_path=os.getcwd())\n",
    "\n",
    "# 2.  Create a datasource (e.g., a connection to a CSV file or database).\n",
    "datasource_name = \"my_pandas_datasource\"\n",
    "pandas_datasource = context.add_datasource(\n",
    "    datasource_name,\n",
    "    class_name=\"Datasource\",\n",
    "    module_name=\"great_expectations.datasource\",\n",
    "    execution_engine={\n",
    "        \"class_name\": \"PandasExecutionEngine\",\n",
    "        \"module_name\": \"great_expectations.execution_engine\",\n",
    "    },\n",
    "    # Define the data you'll be working with.  This is a configuration, not the actual data.\n",
    "    data_connectors={\n",
    "        \"default_inferred_data_connector_name\": {  # You can name this connector\n",
    "            \"class_name\": \"InferredAssetsFileDataConnector\",\n",
    "            \"base_directory\": \"./data\",  # The directory where your data files are located (e.g., CSVs)\n",
    "            \"default_regex\": r\"(.*)\\.csv\",  # A regex to find CSV files.  Adapt to your file naming.\n",
    "            \"group_names\": [\"data_asset_name\"],  # How to group the matched files.\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "# 3. Create a Data Asset (e.g., a specific CSV file)\n",
    "asset_name = \"my_data_asset\"  #  Choose a name for your data asset\n",
    "batch_request = {\n",
    "    \"datasource_name\": datasource_name,\n",
    "    \"data_connector_name\": \"default_inferred_data_connector_name\",\n",
    "    \"data_asset_name\": \"my_data.csv\",  # The name of your CSV file (e.g., \"my_data.csv\")\n",
    "    \"batch_spec_passthrough\": {\n",
    "        \"reader_method\": \"read_csv\",  #  The pandas reader method\n",
    "        \"reader_kwargs\": {\"delimiter\": \",\"}, # Add any reader args\n",
    "    },\n",
    "}\n",
    "\n",
    "# 4. Create an expectation suite.  This is where you'll define your data quality rules.\n",
    "expectation_suite_name = \"my_expectation_suite\"\n",
    "suite = context.create_expectation_suite(\n",
    "    expectation_suite_name=expectation_suite_name, overwrite_existing=True\n",
    ")\n",
    "\n",
    "print(f\"Great Expectations Context Initialized and Expectation Suite '{expectation_suite_name}' created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Handling Missing Values with Conditional Filling\n",
    "# Description: Fill missing values in a specific column based on a condition from another column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  category  value  indicator\n",
      "0        A   10.0       True\n",
      "1        B    NaN      False\n",
      "2        A   20.0       True\n",
      "3        B    NaN      False\n",
      "4        A   30.0      False\n",
      "5        B    NaN       True\n",
      "\n",
      "DataFrame after conditional filling:\n",
      "  category  value  indicator\n",
      "0        A   10.0       True\n",
      "1        B    0.0      False\n",
      "2        A   20.0       True\n",
      "3        B    0.0      False\n",
      "4        A   30.0      False\n",
      "5        B    NaN       True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with missing values\n",
    "data = {'category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
    "        'value': [10, np.nan, 20, np.nan, 30, np.nan],\n",
    "        'indicator': [True, False, True, False, False, True]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Task: Fill missing 'value' with 0 if the corresponding 'indicator' is False\n",
    "\n",
    "df['value'] = np.where(df['indicator'] == False, df['value'].fillna(0), df['value'])\n",
    "\n",
    "print(\"\\nDataFrame after conditional filling:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Removing Outliers by Rescaling\n",
    "# Description: Remove outliers by standardizing a numerical column using z-scores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   value\n",
      "0     20\n",
      "1     22\n",
      "2     25\n",
      "3     23\n",
      "4     21\n",
      "5    150\n",
      "6     24\n",
      "7     26\n",
      "8     22\n",
      "9    -10\n",
      "\n",
      "Outliers (based on |z-score| > 2): [150]\n",
      "\n",
      "DataFrame with Z-scores and Outlier Identification:\n",
      "   value   z_score  is_outlier\n",
      "0     20  0.303893       False\n",
      "1     22  0.254479       False\n",
      "2     25  0.180359       False\n",
      "3     23  0.229773       False\n",
      "4     21  0.279186       False\n",
      "5    150  2.907982        True\n",
      "6     24  0.205066       False\n",
      "7     26  0.155652       False\n",
      "8     22  0.254479       False\n",
      "9    -10  1.045095       False\n",
      "\n",
      "DataFrame with Winsorized Values and their Z-scores:\n",
      "   value  value_winsorized   z_score  z_score_winsorized\n",
      "0     20               NaN  0.303893                 NaN\n",
      "1     22               NaN  0.254479                 NaN\n",
      "2     25               NaN  0.180359                 NaN\n",
      "3     23               NaN  0.229773                 NaN\n",
      "4     21               NaN  0.279186                 NaN\n",
      "5    150        117.628385  2.907982                 NaN\n",
      "6     24               NaN  0.205066                 NaN\n",
      "7     26               NaN  0.155652                 NaN\n",
      "8     22               NaN  0.254479                 NaN\n",
      "9    -10               NaN  1.045095                 NaN\n",
      "\n",
      "DataFrame with Robust Scaled Values:\n",
      "   value   z_score  value_robust_scaled\n",
      "0     20  0.303893            -0.714286\n",
      "1     22  0.254479            -0.142857\n",
      "2     25  0.180359             0.714286\n",
      "3     23  0.229773             0.142857\n",
      "4     21  0.279186            -0.428571\n",
      "5    150  2.907982            36.428571\n",
      "6     24  0.205066             0.428571\n",
      "7     26  0.155652             1.000000\n",
      "8     22  0.254479            -0.142857\n",
      "9    -10  1.045095            -9.285714\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample DataFrame with potential outliers\n",
    "data = {'value': [20, 22, 25, 23, 21, 150, 24, 26, 22, -10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# 1. Calculate Z-scores\n",
    "df['z_score'] = np.abs(stats.zscore(df['value']))\n",
    "\n",
    "# 2. Identify Outliers based on a threshold (e.g., |z-score| > 3)\n",
    "threshold = 2  # You can adjust this threshold\n",
    "outliers = df[df['z_score'] > threshold]['value'].tolist()\n",
    "print(f\"\\nOutliers (based on |z-score| > {threshold}): {outliers}\")\n",
    "\n",
    "# 3. Rescale the column (e.g., using standardization again, but now aware of outliers)\n",
    "# One common approach is to winsorize or cap the outliers instead of direct removal for rescaling.\n",
    "# However, the question asks for removal by rescaling using z-scores, so we'll demonstrate\n",
    "# a way to create a new column where outliers have less extreme z-scores.\n",
    "\n",
    "# Option 1: Create a new column with original values, but mark outliers\n",
    "df['is_outlier'] = df['z_score'] > threshold\n",
    "\n",
    "# Option 2: Replace outlier values with a boundary (winsorizing at the threshold)\n",
    "df_winsorized = df.copy()\n",
    "upper_bound = df['value'].mean() + threshold * df['value'].std()\n",
    "lower_bound = df['value'].mean() - threshold * df['value'].std()\n",
    "df_winsorized.loc[df_winsorized['value'] > upper_bound, 'value_winsorized'] = upper_bound\n",
    "df_winsorized.loc[df_winsorized['value'] < lower_bound, 'value_winsorized'] = lower_bound\n",
    "df_winsorized['z_score_winsorized'] = np.abs(stats.zscore(df_winsorized['value_winsorized']))\n",
    "\n",
    "print(\"\\nDataFrame with Z-scores and Outlier Identification:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDataFrame with Winsorized Values and their Z-scores:\")\n",
    "print(df_winsorized[['value', 'value_winsorized', 'z_score', 'z_score_winsorized']])\n",
    "\n",
    "# Note: Directly \"removing by rescaling using z-scores\" is a bit ambiguous.\n",
    "# Z-scores help identify outliers. To reduce their impact through rescaling,\n",
    "# we often use techniques like winsorizing or robust scaling (e.g., using median and IQR).\n",
    "\n",
    "# Demonstration of Robust Scaling (another way to reduce outlier impact):\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df['value_robust_scaled'] = scaler.fit_transform(df[['value']])\n",
    "\n",
    "print(\"\\nDataFrame with Robust Scaled Values:\")\n",
    "print(df[['value', 'z_score', 'value_robust_scaled']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Applying Data Type Conversion\n",
    "# Description: Convert the 'Age' column to integers after filling missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name   Age      City\n",
      "0    Alice  25.5  New York\n",
      "1      Bob   NaN    London\n",
      "2  Charlie    30     Paris\n",
      "3    David  40.0     Tokyo\n",
      "4      Eve    22    Sydney\n",
      "\n",
      "Data type of 'Age' column: object\n",
      "\n",
      "DataFrame after filling missing 'Age' values:\n",
      "      Name     Age      City  Age_float\n",
      "0    Alice    25.5  New York       25.5\n",
      "1      Bob  29.375    London        NaN\n",
      "2  Charlie      30     Paris       30.0\n",
      "3    David    40.0     Tokyo       40.0\n",
      "4      Eve      22    Sydney       22.0\n",
      "\n",
      "Data type of 'Age' column after filling: object\n",
      "\n",
      "DataFrame after converting 'Age' column to integers:\n",
      "      Name  Age      City  Age_float\n",
      "0    Alice   25  New York       25.5\n",
      "1      Bob   29    London        NaN\n",
      "2  Charlie   30     Paris       30.0\n",
      "3    David   40     Tokyo       40.0\n",
      "4      Eve   22    Sydney       22.0\n",
      "\n",
      "Data type of 'Age' column after conversion: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame with missing age values and incorrect data type\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "        'Age': ['25.5', np.nan, '30', '40.0', '22'],\n",
    "        'City': ['New York', 'London', 'Paris', 'Tokyo', 'Sydney']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(f\"\\nData type of 'Age' column: {df['Age'].dtype}\")\n",
    "\n",
    "# 1. Fill Missing Values in 'Age'\n",
    "# For demonstration, let's fill missing 'Age' with the mean (you might use a different strategy)\n",
    "df['Age_float'] = pd.to_numeric(df['Age'], errors='coerce') # Convert to numeric first to calculate mean\n",
    "mean_age = df['Age_float'].mean()\n",
    "df['Age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame after filling missing 'Age' values:\")\n",
    "print(df)\n",
    "print(f\"\\nData type of 'Age' column after filling: {df['Age'].dtype}\")\n",
    "\n",
    "# 2. Convert 'Age' column to integers\n",
    "# First, ensure the 'Age' column is of a numeric type (float or int)\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='raise') # Raise error if conversion fails\n",
    "\n",
    "# Now, convert to integer\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "\n",
    "print(\"\\nDataFrame after converting 'Age' column to integers:\")\n",
    "print(df)\n",
    "print(f\"\\nData type of 'Age' column after conversion: {df['Age'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: Automating Data Cleaning with Functions\n",
    "# Description: Create a function that automates the process of filling missing values, removing duplicates, and standardizing column names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Name   Age      City   Salary  Data Column\n",
      "0    Alice  25.0  New York  50000.0            1\n",
      "1      Bob   NaN    London  60000.0            2\n",
      "2  Charlie  30.0     Paris      NaN            3\n",
      "3      Bob   NaN    London  60000.0            2\n",
      "4    David  40.0     Tokyo  70000.0            4\n",
      "5      Eve  22.0    Sydney  45000.0            5\n",
      "6    Alice  25.0  New York  50000.0            1\n",
      "\n",
      "Cleaned DataFrame:\n",
      "      name   age      city        salary  data_column\n",
      "0    Alice  25.0  New York  50000.000000            1\n",
      "1      Bob  28.4    London  60000.000000            2\n",
      "2  Charlie  30.0     Paris  55833.333333            3\n",
      "4    David  40.0     Tokyo  70000.000000            4\n",
      "5      Eve  22.0    Sydney  45000.000000            5\n",
      "\n",
      "Cleaned DataFrame (filled with 0):\n",
      "      name   age      city   salary  data_column\n",
      "0    Alice  25.0  New York  50000.0            1\n",
      "1      Bob   0.0    London  60000.0            2\n",
      "2  Charlie  30.0     Paris      0.0            3\n",
      "4    David  40.0     Tokyo  70000.0            4\n",
      "5      Eve  22.0    Sydney  45000.0            5\n",
      "\n",
      "Cleaned DataFrame (filled with median):\n",
      "      name   age      city   salary  data_column\n",
      "0    Alice  25.0  New York  50000.0            1\n",
      "1      Bob  25.0    London  60000.0            2\n",
      "2  Charlie  30.0     Paris  55000.0            3\n",
      "4    David  40.0     Tokyo  70000.0            4\n",
      "5      Eve  22.0    Sydney  45000.0            5\n",
      "\n",
      "Cleaned DataFrame (without standardized column names):\n",
      "      Name   Age      City        Salary  Data Column\n",
      "0    Alice  25.0  New York  50000.000000            1\n",
      "1      Bob  28.4    London  60000.000000            2\n",
      "2  Charlie  30.0     Paris  55833.333333            3\n",
      "4    David  40.0     Tokyo  70000.000000            4\n",
      "5      Eve  22.0    Sydney  45000.000000            5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def automate_data_cleaning(df, missing_value_strategy=None, columns_to_fill=None, fill_value=None,\n",
    "                           columns_to_impute_mean=None, columns_to_impute_median=None,\n",
    "                           remove_duplicate_subset=None, standardize_column_names=True):\n",
    "    \"\"\"\n",
    "    Automates common data cleaning tasks: filling missing values, removing duplicates,\n",
    "    and standardizing column names.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to be cleaned.\n",
    "        missing_value_strategy (str, optional): Strategy for handling missing values.\n",
    "            Options: 'fill_value', 'mean', 'median'. Defaults to None.\n",
    "        columns_to_fill (list, optional): List of columns to fill with a specific value.\n",
    "            Required if missing_value_strategy='fill_value'. Defaults to None.\n",
    "        fill_value (any, optional): The value to fill missing values with.\n",
    "            Required if missing_value_strategy='fill_value'. Defaults to None.\n",
    "        columns_to_impute_mean (list, optional): List of columns to fill missing values\n",
    "            with the mean. Required if missing_value_strategy='mean'. Defaults to None.\n",
    "        columns_to_impute_median (list, optional): List of columns to fill missing values\n",
    "            with the median. Required if missing_value_strategy='median'. Defaults to None.\n",
    "        remove_duplicate_subset (list, optional): List of columns to consider when\n",
    "            identifying duplicate rows. If None, all columns are considered.\n",
    "            Defaults to None.\n",
    "        standardize_column_names (bool, optional): Whether to standardize column names\n",
    "            (lowercase and replace spaces with underscores). Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    cleaned_df = df.copy()\n",
    "\n",
    "    # Handle Missing Values\n",
    "    if missing_value_strategy == 'fill_value':\n",
    "        if columns_to_fill is None or fill_value is None:\n",
    "            print(\"Warning: 'columns_to_fill' and 'fill_value' must be specified for 'fill_value' strategy.\")\n",
    "        else:\n",
    "            for col in columns_to_fill:\n",
    "                if col in cleaned_df.columns:\n",
    "                    cleaned_df[col].fillna(fill_value, inplace=True)\n",
    "                else:\n",
    "                    print(f\"Warning: Column '{col}' not found in DataFrame for fillna.\")\n",
    "    elif missing_value_strategy == 'mean':\n",
    "        if columns_to_impute_mean is None:\n",
    "            print(\"Warning: 'columns_to_impute_mean' must be specified for 'mean' imputation.\")\n",
    "        else:\n",
    "            for col in columns_to_impute_mean:\n",
    "                if col in cleaned_df.columns:\n",
    "                    cleaned_df[col].fillna(cleaned_df[col].mean(), inplace=True)\n",
    "                else:\n",
    "                    print(f\"Warning: Column '{col}' not found in DataFrame for mean imputation.\")\n",
    "    elif missing_value_strategy == 'median':\n",
    "        if columns_to_impute_median is None:\n",
    "            print(\"Warning: 'columns_to_impute_median' must be specified for 'median' imputation.\")\n",
    "        else:\n",
    "            for col in columns_to_impute_median:\n",
    "                if col in cleaned_df.columns:\n",
    "                    cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n",
    "                else:\n",
    "                    print(f\"Warning: Column '{col}' not found in DataFrame for median imputation.\")\n",
    "    elif missing_value_strategy is not None:\n",
    "        print(f\"Warning: Unknown missing_value_strategy: '{missing_value_strategy}'. Skipping missing value handling.\")\n",
    "\n",
    "    # Remove Duplicates\n",
    "    cleaned_df.drop_duplicates(subset=remove_duplicate_subset, inplace=True)\n",
    "\n",
    "    # Standardize Column Names\n",
    "    if standardize_column_names:\n",
    "        cleaned_df.columns = cleaned_df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "# Sample DataFrame with missing values and duplicates\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie', 'Bob', 'David', 'Eve', 'Alice'],\n",
    "        'Age': [25, np.nan, 30, np.nan, 40, 22, 25],\n",
    "        'City': ['New York', 'London', 'Paris', 'London', 'Tokyo', 'Sydney', 'New York'],\n",
    "        'Salary': [50000, 60000, np.nan, 60000, 70000, 45000, 50000],\n",
    "        'Data Column': [1, 2, 3, 2, 4, 5, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Clean the DataFrame\n",
    "cleaned_df = automate_data_cleaning(\n",
    "    df.copy(),\n",
    "    missing_value_strategy='mean',\n",
    "    columns_to_impute_mean=['Age', 'Salary'],\n",
    "    remove_duplicate_subset=['Name', 'City'],\n",
    "    standardize_column_names=True\n",
    ")\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(cleaned_df)\n",
    "\n",
    "# Example with different missing value strategy\n",
    "cleaned_df_fill = automate_data_cleaning(\n",
    "    df.copy(),\n",
    "    missing_value_strategy='fill_value',\n",
    "    columns_to_fill=['Age', 'Salary'],\n",
    "    fill_value=0,\n",
    "    remove_duplicate_subset=['Name', 'City'],\n",
    "    standardize_column_names=True\n",
    ")\n",
    "\n",
    "print(\"\\nCleaned DataFrame (filled with 0):\")\n",
    "print(cleaned_df_fill)\n",
    "\n",
    "# Example with median imputation\n",
    "cleaned_df_median = automate_data_cleaning(\n",
    "    df.copy(),\n",
    "    missing_value_strategy='median',\n",
    "    columns_to_impute_median=['Age', 'Salary'],\n",
    "    remove_duplicate_subset=['Name', 'City'],\n",
    "    standardize_column_names=True\n",
    ")\n",
    "\n",
    "print(\"\\nCleaned DataFrame (filled with median):\")\n",
    "print(cleaned_df_median)\n",
    "\n",
    "# Example without standardizing column names\n",
    "cleaned_df_no_std_cols = automate_data_cleaning(\n",
    "    df.copy(),\n",
    "    missing_value_strategy='mean',\n",
    "    columns_to_impute_mean=['Age', 'Salary'],\n",
    "    remove_duplicate_subset=['Name', 'City'],\n",
    "    standardize_column_names=False\n",
    ")\n",
    "\n",
    "print(\"\\nCleaned DataFrame (without standardized column names):\")\n",
    "print(cleaned_df_no_std_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Complex Data Normalization\n",
    "# Description: Normalize a numeric column to a range using min-max scaling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  Product  Price\n",
      "0       A    100\n",
      "1       B    250\n",
      "2       C    150\n",
      "3       D    300\n",
      "4       E    200\n",
      "\n",
      "DataFrame with Min-Max Normalized 'Price' column:\n",
      "  Product  Price  Price_Normalized\n",
      "0       A    100              0.00\n",
      "1       B    250              0.75\n",
      "2       C    150              0.25\n",
      "3       D    300              1.00\n",
      "4       E    200              0.50\n",
      "\n",
      "Minimum Price (Original): 100\n",
      "Maximum Price (Original): 300\n",
      "Minimum Price (Normalized): 0.0\n",
      "Maximum Price (Normalized): 1.0\n",
      "\n",
      "DataFrame with Min-Max Normalized 'Price' column (range 0-10):\n",
      "  Product  Price  Price_Normalized  Price_Normalized_0_10\n",
      "0       A    100              0.00                    0.0\n",
      "1       B    250              0.75                    7.5\n",
      "2       C    150              0.25                    2.5\n",
      "3       D    300              1.00                   10.0\n",
      "4       E    200              0.50                    5.0\n",
      "\n",
      "Minimum Price (Normalized 0-10): 0.0\n",
      "Maximum Price (Normalized 0-10): 10.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Sample DataFrame with a numeric column to normalize\n",
    "data = {'Product': ['A', 'B', 'C', 'D', 'E'],\n",
    "        'Price': [100, 250, 150, 300, 200]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# 1. Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 2. Fit the scaler to the data and transform the column\n",
    "# MinMaxScaler expects a 2D array, so we reshape the 'Price' column\n",
    "df['Price_Normalized'] = scaler.fit_transform(df[['Price']])\n",
    "\n",
    "print(\"\\nDataFrame with Min-Max Normalized 'Price' column:\")\n",
    "print(df)\n",
    "\n",
    "# To understand the scaling, let's look at the min and max of the original and normalized columns\n",
    "print(f\"\\nMinimum Price (Original): {df['Price'].min()}\")\n",
    "print(f\"Maximum Price (Original): {df['Price'].max()}\")\n",
    "print(f\"Minimum Price (Normalized): {df['Price_Normalized'].min()}\")\n",
    "print(f\"Maximum Price (Normalized): {df['Price_Normalized'].max()}\")\n",
    "\n",
    "# You can also specify a different target range if needed\n",
    "target_range_scaler = MinMaxScaler(feature_range=(0, 10)) # Normalize to a range between 0 and 10\n",
    "df['Price_Normalized_0_10'] = target_range_scaler.fit_transform(df[['Price']])\n",
    "\n",
    "print(\"\\nDataFrame with Min-Max Normalized 'Price' column (range 0-10):\")\n",
    "print(df)\n",
    "print(f\"\\nMinimum Price (Normalized 0-10): {df['Price_Normalized_0_10'].min()}\")\n",
    "print(f\"Maximum Price (Normalized 0-10): {df['Price_Normalized_0_10'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

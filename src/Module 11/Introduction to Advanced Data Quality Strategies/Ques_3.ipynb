{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning for Data Quality Prediction\n",
    "**Description**: Use a machine learning model to predict data quality issues.\n",
    "\n",
    "**Steps**:\n",
    "1. Create a mock dataset with features and label (quality issue/label: 0: good, 1: issue).\n",
    "2. Train a machine learning model.\n",
    "3. Evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mock Dataset:\n",
      "   missing_values_count  outlier_score  data_type_consistency  \\\n",
      "0                     6       0.256016                      0   \n",
      "1                     3       0.726096                      0   \n",
      "2                     7       0.592963                      0   \n",
      "3                     4       0.102213                      0   \n",
      "4                     6       0.918751                      0   \n",
      "\n",
      "   range_violation_count  unique_value_ratio  format_consistency  \\\n",
      "0                      4            0.570612                   0   \n",
      "1                      0            0.785439                   0   \n",
      "2                      1            0.592635                   0   \n",
      "3                      2            0.639322                   0   \n",
      "4                      1            0.609355                   0   \n",
      "\n",
      "   quality_issue  \n",
      "0              1  \n",
      "1              0  \n",
      "2              1  \n",
      "3              0  \n",
      "4              1  \n",
      "\n",
      "Distribution of Data Quality Labels:\n",
      "quality_issue\n",
      "1    672\n",
      "0    328\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Random Forest Classifier model trained.\n",
      "\n",
      "Model Evaluation:\n",
      "Accuracy: 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        95\n",
      "           1       1.00      1.00      1.00       205\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task: Use a machine learning model to predict data quality issues.\n",
    "# Steps:\n",
    "# 1. Create a mock dataset with features and label (quality issue/label: 0: good, 1: issue).\n",
    "# 2. Train a machine learning model.\n",
    "# 3. Evaluate the model performance.\n",
    "\n",
    "# 1. Create a mock dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Features that might indicate data quality issues\n",
    "df = pd.DataFrame({\n",
    "    'missing_values_count': np.random.randint(0, 10, n_samples),\n",
    "    'outlier_score': np.random.rand(n_samples),\n",
    "    'data_type_consistency': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]), # 1 if inconsistent\n",
    "    'range_violation_count': np.random.randint(0, 5, n_samples),\n",
    "    'unique_value_ratio': np.random.uniform(0.5, 1.0, n_samples),\n",
    "    'format_consistency': np.random.choice([0, 1], n_samples, p=[0.95, 0.05]) # 1 if inconsistent format\n",
    "})\n",
    "\n",
    "# Create a label based on a combination of these features\n",
    "# Higher missing values, outlier score, inconsistencies, and range violations\n",
    "# are more likely to indicate a data quality issue.\n",
    "df['quality_issue'] = (\n",
    "    (df['missing_values_count'] > 5) |\n",
    "    (df['outlier_score'] > 0.8) |\n",
    "    (df['data_type_consistency'] == 1) |\n",
    "    (df['range_violation_count'] > 3) |\n",
    "    (df['format_consistency'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "print(\"Mock Dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nDistribution of Data Quality Labels:\")\n",
    "print(df['quality_issue'].value_counts())\n",
    "\n",
    "# 2. Train a machine learning model\n",
    "# Separate features (X) and label (y)\n",
    "X = df.drop('quality_issue', axis=1)\n",
    "y = df['quality_issue']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train a Random Forest Classifier model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nRandom Forest Classifier model trained.\")\n",
    "\n",
    "# 3. Evaluate the model performance\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness:\n",
      " Name     100.000000\n",
      "Email     83.333333\n",
      "Age       83.333333\n",
      "dtype: float64\n",
      "\n",
      "Email Validity (contains '@'): 66.66666666666666 %\n",
      "\n",
      "Email Uniqueness (count of distinct emails): 4\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "# Sample CSV data as a string\n",
    "csv_data = \"\"\"Name,Email,Age\n",
    "Alice,alice@example.com,30\n",
    "Bob,bob@example.com,25\n",
    "Charlie,charlie@example.com,\n",
    "David,,40\n",
    "Eve,eve.example.com,35\n",
    "Alice,alice@example.com,30\n",
    "\"\"\"\n",
    "\n",
    "# Read the CSV data into a pandas DataFrame\n",
    "df = pd.read_csv(io.StringIO(csv_data))\n",
    "\n",
    "# 1. Completeness: Percentage of non-null values for each column\n",
    "completeness = df.notnull().sum() / len(df) * 100\n",
    "print(\"Completeness:\\n\", completeness)\n",
    "\n",
    "# 2. Validity (for Email column): Percentage of email fields containing '@'\n",
    "total_emails = len(df['Email'])\n",
    "valid_emails = df['Email'].astype(str).str.contains('@').sum()\n",
    "validity_email = (valid_emails / total_emails) * 100\n",
    "print(\"\\nEmail Validity (contains '@'):\", validity_email, \"%\")\n",
    "\n",
    "# 3. Uniqueness (for Email column): Count of distinct entries\n",
    "unique_emails = df['Email'].nunique()\n",
    "print(\"\\nEmail Uniqueness (count of distinct emails):\", unique_emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Score: 83.33333333333334 %\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Completeness values from Task 1\n",
    "completeness_name = completeness['Name']\n",
    "completeness_email = completeness['Email']\n",
    "completeness_age = completeness['Age']\n",
    "\n",
    "# Email validity from Task 1\n",
    "# Ensure validity_email is defined from the previous step\n",
    "if 'validity_email' not in locals():\n",
    "    total_emails = len(df['Email'])\n",
    "    valid_emails = df['Email'].astype(str).str.contains('@').sum()\n",
    "    validity_email = (valid_emails / total_emails) * 100\n",
    "\n",
    "# Calculate the average data quality score\n",
    "data_quality_score = (completeness_name + completeness_email + completeness_age + validity_email) / 4\n",
    "\n",
    "print(\"Data Quality Score:\", data_quality_score, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: great_expectations in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: altair<5.0.0,>=4.2.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (4.2.2)\n",
      "Requirement already satisfied: cryptography>=3.2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (44.0.3)\n",
      "Requirement already satisfied: jinja2>=3 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (4.23.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.7.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (3.26.1)\n",
      "Requirement already satisfied: mistune>=0.8.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (3.1.3)\n",
      "Requirement already satisfied: packaging in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (25.0)\n",
      "Requirement already satisfied: posthog<4,>3 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (3.25.0)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (2.11.4)\n",
      "Requirement already satisfied: pyparsing>=2.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.20 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (2.32.3)\n",
      "Requirement already satisfied: ruamel.yaml>=0.16 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (0.18.10)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (1.15.3)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (4.13.2)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.2,>=1.3.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great_expectations) (2.1.4)\n",
      "Requirement already satisfied: entrypoints in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from altair<5.0.0,>=4.2.1->great_expectations) (0.4)\n",
      "Requirement already satisfied: toolz in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from altair<5.0.0,>=4.2.1->great_expectations) (1.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pandas<2.2,>=1.3.0->great_expectations) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pandas<2.2,>=1.3.0->great_expectations) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.17.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from posthog<4,>3->great_expectations) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from requests>=2.20->great_expectations) (2025.4.26)\n",
      "Requirement already satisfied: cffi>=1.12 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from cryptography>=3.2->great_expectations) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.2->great_expectations) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jinja2>=3->great_expectations) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jsonschema>=2.5.1->great_expectations) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pydantic>=1.10.7->great_expectations) (0.4.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ruamel.yaml>=0.16->great_expectations) (0.2.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install great_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'great_expectations.dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code from here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PandasDataset\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Our sample CSV data again\u001b[39;00m\n\u001b[1;32m      6\u001b[0m csv_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mName,Email,Age\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mAlice,alice@example.com,30\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mBob,bob@example.com,25\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mAlice,alice@example.com,30\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'great_expectations.dataset'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from great_expectations.dataset import PandasDataset\n",
    "\n",
    "# Our sample CSV data again\n",
    "csv_data = \"\"\"Name,Email,Age\n",
    "Alice,alice@example.com,30\n",
    "Bob,bob@example.com,25\n",
    "Charlie,charlie@example.com,\n",
    "David,,40\n",
    "Eve,eve.example.com,35\n",
    "Alice,alice@example.com,30\n",
    "\"\"\"\n",
    "\n",
    "# Read the CSV data into a pandas DataFrame\n",
    "df = pd.read_csv(io.StringIO(csv_data))\n",
    "\n",
    "# Create a Great Expectations dataset from the pandas DataFrame\n",
    "ge_df = PandasDataset(df)\n",
    "\n",
    "# Define Expectations for Completeness\n",
    "\n",
    "# Expect 'Name' column to have no missing values (100% complete)\n",
    "ge_df.expect_column_values_to_not_be_null(column=\"Name\")\n",
    "\n",
    "# Expect 'Email' column to have at least 80% completeness\n",
    "ge_df.expect_column_proportion_of_non_null_values_to_be_at_least(\n",
    "    column=\"Email\", value=0.8\n",
    ")\n",
    "\n",
    "# Expect 'Age' column to have at least 70% completeness\n",
    "ge_df.expect_column_proportion_of_non_null_values_to_be_at_least(\n",
    "    column=\"Age\", value=0.7\n",
    ")\n",
    "\n",
    "# You can add more expectations here for other quality aspects like validity and uniqueness\n",
    "\n",
    "# To see the defined expectations (optional)\n",
    "print(ge_df.list_expectation_suite())\n",
    "\n",
    "# To validate the data against the defined expectations (optional for this task, but good to know)\n",
    "validation_results = ge_df.validate()\n",
    "print(\"\\nValidation Results:\\n\", validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ge_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code from here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Continue from Task 3\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define an expectation for Email validity (contains '@')\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mge_df\u001b[49m\u001b[38;5;241m.\u001b[39mexpect_column_values_to_match_regex(\n\u001b[1;32m      6\u001b[0m     column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmail\u001b[39m\u001b[38;5;124m\"\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.+@.+\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Define an expectation for Email uniqueness\u001b[39;00m\n\u001b[1;32m     10\u001b[0m ge_df\u001b[38;5;241m.\u001b[39mexpect_column_values_to_be_unique(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmail\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ge_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Continue from Task 3\n",
    "\n",
    "# Define an expectation for Email validity (contains '@')\n",
    "ge_df.expect_column_values_to_match_regex(\n",
    "    column=\"Email\", regex=r\".+@.+\"\n",
    ")\n",
    "\n",
    "# Define an expectation for Email uniqueness\n",
    "ge_df.expect_column_values_to_be_unique(column=\"Email\")\n",
    "\n",
    "# 1. Validate the data against the defined expectations\n",
    "validation_results = ge_df.validate()\n",
    "print(\"Validation Results:\\n\", validation_results)\n",
    "\n",
    "# 2. Generate an HTML Report (basic, without full Great Expectations setup)\n",
    "# For a more comprehensive HTML report, you'd typically initialize a DataContext\n",
    "# in Great Expectations. However, for this basic exercise, we can extract\n",
    "# the validation results and create a simple HTML output.\n",
    "\n",
    "html_report = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Data Quality Validation Report</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Data Quality Validation Report</h1>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <th>Expectation</th>\n",
    "            <th>Success</th>\n",
    "            <th>Details</th>\n",
    "        </tr>\n",
    "\"\"\"\n",
    "\n",
    "for result in validation_results['results']:\n",
    "    expectation = result['expectation_config']['expectation_type']\n",
    "    column = result['expectation_config'].get('kwargs', {}).get('column', 'N/A')\n",
    "    success = result['success']\n",
    "    details = result.get('result', {}).get('unexpected_percent', 'N/A')\n",
    "    if details != 'N/A':\n",
    "        details = f\"{details:.2f}% unexpected\"\n",
    "\n",
    "    html_report += f\"\"\"\n",
    "        <tr>\n",
    "            <td>{expectation} (Column: {column})</td>\n",
    "            <td>{'Yes' if success else 'No'}</td>\n",
    "            <td>{details}</td>\n",
    "        </tr>\n",
    "    \"\"\"\n",
    "\n",
    "html_report += \"\"\"\n",
    "    </table>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save the HTML report to a file\n",
    "with open(\"data_quality_report.html\", \"w\") as f:\n",
    "    f.write(html_report)\n",
    "\n",
    "print(\"\\nBasic HTML report 'data_quality_report.html' generated.\")\n",
    "\n",
    "# Note: For a more feature-rich and automated HTML report, you would typically\n",
    "# initialize a Great Expectations DataContext and configure data docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

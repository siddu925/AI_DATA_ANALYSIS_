{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Management for Data Quality\n",
    "**Description**: Store and use metadata to manage data quality in a pipeline.\n",
    "\n",
    "**Steps**:\n",
    "1. Load metadata\n",
    "2. Load data\n",
    "3. Use metadata to validate data quality\n",
    "4. Show valid data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample metadata created at: data_quality_metadata.json\n",
      "Sample data created at: data_to_validate.csv\n",
      "Metadata loaded successfully from: data_quality_metadata.json\n",
      "\n",
      "Metadata:\n",
      "{\n",
      "    \"description\": \"Metadata for validating customer data\",\n",
      "    \"columns\": {\n",
      "        \"customer_id\": {\n",
      "            \"data_type\": \"numeric\",\n",
      "            \"not_null\": true\n",
      "        },\n",
      "        \"name\": {\n",
      "            \"data_type\": \"string\",\n",
      "            \"not_null\": true\n",
      "        },\n",
      "        \"age\": {\n",
      "            \"data_type\": \"numeric\",\n",
      "            \"min\": 18,\n",
      "            \"max\": 99\n",
      "        },\n",
      "        \"city\": {\n",
      "            \"data_type\": \"string\",\n",
      "            \"allowed_values\": [\n",
      "                \"Bengaluru\",\n",
      "                \"Mumbai\",\n",
      "                \"Delhi\"\n",
      "            ]\n",
      "        },\n",
      "        \"is_active\": {\n",
      "            \"data_type\": \"boolean\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "Data loaded successfully from: data_to_validate.csv\n",
      "\n",
      "Sample of loaded data:\n",
      "   customer_id     name    age       city is_active\n",
      "0            1    Alice   30.0  Bengaluru      True\n",
      "1            2      Bob   15.0     London     False\n",
      "2            3  Charlie   45.0      Delhi      True\n",
      "3            4    David   22.0     Mumbai     False\n",
      "4            5      Eve  100.0  Bengaluru         1\n",
      "\n",
      "Data Quality Validation Errors:\n",
      "- V\n",
      "- a\n",
      "- l\n",
      "- i\n",
      "- d\n",
      "- a\n",
      "- t\n",
      "- i\n",
      "- o\n",
      "- n\n",
      "-  \n",
      "- E\n",
      "- r\n",
      "- r\n",
      "- o\n",
      "- r\n",
      "- :\n",
      "-  \n",
      "- C\n",
      "- o\n",
      "- l\n",
      "- u\n",
      "- m\n",
      "- n\n",
      "-  \n",
      "- '\n",
      "- a\n",
      "- g\n",
      "- e\n",
      "- '\n",
      "-  \n",
      "- h\n",
      "- a\n",
      "- s\n",
      "-  \n",
      "- v\n",
      "- a\n",
      "- l\n",
      "- u\n",
      "- e\n",
      "- s\n",
      "-  \n",
      "- b\n",
      "- e\n",
      "- l\n",
      "- o\n",
      "- w\n",
      "-  \n",
      "- m\n",
      "- i\n",
      "- n\n",
      "- i\n",
      "- m\n",
      "- u\n",
      "- m\n",
      "-  \n",
      "- (\n",
      "- 1\n",
      "- 8\n",
      "- .\n",
      "- 0\n",
      "- )\n",
      "-  \n",
      "- i\n",
      "- n\n",
      "-  \n",
      "- r\n",
      "- o\n",
      "- w\n",
      "- s\n",
      "- :\n",
      "-  \n",
      "- [\n",
      "- 1\n",
      "- ]\n",
      "- V\n",
      "- a\n",
      "- l\n",
      "- i\n",
      "- d\n",
      "- a\n",
      "- t\n",
      "- i\n",
      "- o\n",
      "- n\n",
      "-  \n",
      "- E\n",
      "- r\n",
      "- r\n",
      "- o\n",
      "- r\n",
      "- :\n",
      "-  \n",
      "- C\n",
      "- o\n",
      "- l\n",
      "- u\n",
      "- m\n",
      "- n\n",
      "-  \n",
      "- '\n",
      "- a\n",
      "- g\n",
      "- e\n",
      "- '\n",
      "-  \n",
      "- h\n",
      "- a\n",
      "- s\n",
      "-  \n",
      "- v\n",
      "- a\n",
      "- l\n",
      "- u\n",
      "- e\n",
      "- s\n",
      "-  \n",
      "- a\n",
      "- b\n",
      "- o\n",
      "- v\n",
      "- e\n",
      "-  \n",
      "- m\n",
      "- a\n",
      "- x\n",
      "- i\n",
      "- m\n",
      "- u\n",
      "- m\n",
      "-  \n",
      "- (\n",
      "- 9\n",
      "- 9\n",
      "- .\n",
      "- 0\n",
      "- )\n",
      "-  \n",
      "- i\n",
      "- n\n",
      "-  \n",
      "- r\n",
      "- o\n",
      "- w\n",
      "- s\n",
      "- :\n",
      "-  \n",
      "- [\n",
      "- 4\n",
      "- ]\n",
      "- Validation Error: Column 'is_active' expected to be boolean, but is 'object'.\n",
      "\n",
      "Showing valid data after filtering based on metadata constraints.\n",
      "\n",
      "Valid Data:\n",
      "   customer_id     name   age       city  is_active\n",
      "0            1    Alice  30.0  Bengaluru       True\n",
      "2            3  Charlie  45.0      Delhi       True\n",
      "3            4    David  22.0     Mumbai       True\n",
      "\n",
      "Shape of valid data: (3, 5)\n"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def manage_data_quality_with_metadata(metadata_file, data_file):\n",
    "    \"\"\"\n",
    "    Loads metadata and data, uses the metadata to validate data quality,\n",
    "    and shows the valid data.\n",
    "\n",
    "    Args:\n",
    "        metadata_file (str): Path to the JSON file containing metadata.\n",
    "        data_file (str): Path to the CSV file containing the data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Load metadata\n",
    "        with open(metadata_file, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"Metadata loaded successfully from: {metadata_file}\\n\")\n",
    "        print(\"Metadata:\")\n",
    "        print(json.dumps(metadata, indent=4))\n",
    "\n",
    "        # Step 2: Load data\n",
    "        df = pd.read_csv(data_file)\n",
    "        print(f\"\\nData loaded successfully from: {data_file}\\n\")\n",
    "        print(\"Sample of loaded data:\")\n",
    "        print(df.head())\n",
    "\n",
    "        # Step 3: Use metadata to validate data quality\n",
    "        valid_data = df.copy()\n",
    "        validation_errors = []\n",
    "\n",
    "        for column, constraints in metadata.get('columns', {}).items():\n",
    "            if column not in valid_data.columns:\n",
    "                validation_errors.append(f\"Error: Column '{column}' defined in metadata not found in data.\")\n",
    "                continue\n",
    "\n",
    "            for constraint_type, constraint_value in constraints.items():\n",
    "                if constraint_type == 'data_type':\n",
    "                    expected_type = constraint_value\n",
    "                    actual_type = valid_data[column].dtype\n",
    "                    # Simple type check, more robust checks might be needed\n",
    "                    if expected_type == 'numeric' and not pd.api.types.is_numeric_dtype(actual_type):\n",
    "                        validation_errors.append(f\"Validation Error: Column '{column}' expected to be numeric, but is '{actual_type}'.\")\n",
    "                        valid_data[column] = pd.to_numeric(valid_data[column], errors='coerce') # Try to convert\n",
    "                    elif expected_type == 'string' and not pd.api.types.is_string_dtype(actual_type):\n",
    "                        validation_errors.append(f\"Validation Error: Column '{column}' expected to be string, but is '{actual_type}'.\")\n",
    "                        valid_data[column] = valid_data[column].astype(str)\n",
    "                    elif expected_type == 'boolean' and not pd.api.types.is_bool_dtype(actual_type):\n",
    "                        validation_errors.append(f\"Validation Error: Column '{column}' expected to be boolean, but is '{actual_type}'.\")\n",
    "                        # Simple boolean conversion, might need more sophisticated handling\n",
    "                        valid_data[column] = valid_data[column].astype(bool)\n",
    "                elif constraint_type == 'min':\n",
    "                    try:\n",
    "                        min_val = float(constraint_value)\n",
    "                        invalid_rows = valid_data[valid_data[column] < min_val]\n",
    "                        if not invalid_rows.empty:\n",
    "                            validation_errors.extend(f\"Validation Error: Column '{column}' has values below minimum ({min_val}) in rows: {invalid_rows.index.tolist()}\")\n",
    "                            valid_data = valid_data[valid_data[column] >= min_val] # Filter out invalid rows\n",
    "                    except ValueError:\n",
    "                        validation_errors.append(f\"Error: Invalid 'min' value in metadata for column '{column}'.\")\n",
    "                elif constraint_type == 'max':\n",
    "                    try:\n",
    "                        max_val = float(constraint_value)\n",
    "                        invalid_rows = valid_data[valid_data[column] > max_val]\n",
    "                        if not invalid_rows.empty:\n",
    "                            validation_errors.extend(f\"Validation Error: Column '{column}' has values above maximum ({max_val}) in rows: {invalid_rows.index.tolist()}\")\n",
    "                            valid_data = valid_data[valid_data[column] <= max_val] # Filter out invalid rows\n",
    "                    except ValueError:\n",
    "                        validation_errors.append(f\"Error: Invalid 'max' value in metadata for column '{column}'.\")\n",
    "                elif constraint_type == 'allowed_values':\n",
    "                    allowed_list = constraint_value\n",
    "                    invalid_rows = valid_data[~valid_data[column].isin(allowed_list)]\n",
    "                    if not invalid_rows.empty:\n",
    "                        validation_errors.extend(f\"Validation Error: Column '{column}' has values not in allowed list ({allowed_list}) in rows: {invalid_rows.index.tolist()}\")\n",
    "                        valid_data = valid_data[valid_data[column].isin(allowed_list)] # Filter out invalid rows\n",
    "                elif constraint_type == 'not_null':\n",
    "                    if constraint_value is True:\n",
    "                        invalid_rows = valid_data[valid_data[column].isnull()]\n",
    "                        if not invalid_rows.empty:\n",
    "                            validation_errors.extend(f\"Validation Error: Column '{column}' has null values in rows: {invalid_rows.index.tolist()}\")\n",
    "                            valid_data = valid_data[valid_data[column].notnull()] # Filter out rows with nulls\n",
    "\n",
    "        if validation_errors:\n",
    "            print(\"\\nData Quality Validation Errors:\")\n",
    "            for error in validation_errors:\n",
    "                print(f\"- {error}\")\n",
    "            print(\"\\nShowing valid data after filtering based on metadata constraints.\")\n",
    "        else:\n",
    "            print(\"\\nData Quality Validation Passed. All data conforms to the metadata constraints.\")\n",
    "\n",
    "        # Step 4: Show valid data\n",
    "        print(\"\\nValid Data:\")\n",
    "        print(valid_data.head())\n",
    "        print(f\"\\nShape of valid data: {valid_data.shape}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: One or both files not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Invalid JSON format in metadata file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example Usage:\n",
    "metadata_file = 'data_quality_metadata.json'\n",
    "data_file = 'data_to_validate.csv'\n",
    "\n",
    "# Create a sample metadata file\n",
    "sample_metadata = {\n",
    "    \"description\": \"Metadata for validating customer data\",\n",
    "    \"columns\": {\n",
    "        \"customer_id\": {\"data_type\": \"numeric\", \"not_null\": True},\n",
    "        \"name\": {\"data_type\": \"string\", \"not_null\": True},\n",
    "        \"age\": {\"data_type\": \"numeric\", \"min\": 18, \"max\": 99},\n",
    "        \"city\": {\"data_type\": \"string\", \"allowed_values\": [\"Bengaluru\", \"Mumbai\", \"Delhi\"]},\n",
    "        \"is_active\": {\"data_type\": \"boolean\"}\n",
    "    }\n",
    "}\n",
    "with open(metadata_file, 'w') as f:\n",
    "    json.dump(sample_metadata, f, indent=4)\n",
    "print(f\"Sample metadata created at: {metadata_file}\")\n",
    "\n",
    "# Create a sample data file\n",
    "sample_data = {\n",
    "    'customer_id': [1, 2, 3, 4, 5, 6],\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'age': [30, 15, 45, 22, 100, None],\n",
    "    'city': ['Bengaluru', 'London', 'Delhi', 'Mumbai', 'Bengaluru', 'Pune'],\n",
    "    'is_active': [True, False, 'True', 'False', 1, 0]\n",
    "}\n",
    "df_sample = pd.DataFrame(sample_data)\n",
    "df_sample.to_csv(data_file, index=False)\n",
    "print(f\"Sample data created at: {data_file}\")\n",
    "\n",
    "# Run the data quality management function\n",
    "manage_data_quality_with_metadata(metadata_file, data_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

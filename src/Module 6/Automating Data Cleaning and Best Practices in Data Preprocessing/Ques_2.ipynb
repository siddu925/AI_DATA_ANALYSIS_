{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Complete Pipeline for a Dataset\n",
    "1. Objective: Build a complex pipeline with multiple transformations.\n",
    "2. Steps:\n",
    "    - Load a sample dataset.\n",
    "    - Define a transformation pipeline with both imputation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame with missing values:\n",
      "   feature1  feature2  feature3 category\n",
      "0      10.0       5.0       1.0        A\n",
      "1       NaN      15.0       2.0        B\n",
      "2      30.0       NaN       1.5        A\n",
      "3      40.0      35.0       2.5        C\n",
      "4      50.0      45.0       NaN        B\n",
      "\n",
      "DataFrame after imputation and scaling:\n",
      "   feature1  feature2  feature3 category\n",
      "0 -1.700840 -1.414214      -1.5        A\n",
      "1  0.000000 -0.707107       0.5        B\n",
      "2 -0.188982  0.000000      -0.5        A\n",
      "3  0.566947  0.707107       1.5        C\n",
      "4  1.322876  1.414214       0.0        B\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load a sample dataset\n",
    "data = {'feature1': [10, np.nan, 30, 40, 50],\n",
    "        'feature2': [5, 15, np.nan, 35, 45],\n",
    "        'feature3': [1.0, 2.0, 1.5, 2.5, np.nan],\n",
    "        'category': ['A', 'B', 'A', 'C', 'B']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame with missing values:\")\n",
    "print(df)\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = ['feature1', 'feature2', 'feature3']\n",
    "categorical_features = ['category']\n",
    "\n",
    "# 2. Define a transformation pipeline with both imputation and scaling\n",
    "\n",
    "# Pipeline for numerical features: Impute missing values with the mean, then scale\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# For categorical features, we'll just impute missing values with the most frequent\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Apply the numerical pipeline to the numerical features\n",
    "df[numerical_features] = numerical_pipeline.fit_transform(df[numerical_features])\n",
    "\n",
    "# Apply the categorical pipeline to the categorical features\n",
    "df[categorical_features] = categorical_pipeline.fit_transform(df[categorical_features])\n",
    "\n",
    "# Display the transformed DataFrame\n",
    "print(\"\\nDataFrame after imputation and scaling:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Imputation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scaling Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combined Transformation Function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

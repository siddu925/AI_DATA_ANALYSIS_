{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Automated Data Profiling\n",
    "\n",
    "**Steps**:\n",
    "1. Using Pandas-Profiling\n",
    "    - Generate a profile report for an existing CSV file.\n",
    "    - Customize the profile report to include correlations.\n",
    "    - Profile a specific subset of columns.\n",
    "2. Using Great Expectations\n",
    "    - Create a basic expectation suite for your data.\n",
    "    - Validate data against an expectation suite.\n",
    "    - Add multiple expectations to a suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Real-time Monitoring of Data Quality\n",
    "\n",
    "**Steps**:\n",
    "1. Setting up Alerts for Quality Drops\n",
    "    - Use the logging library to set up a basic alert on failed expectations.\n",
    "    - Implementing alerts using email notifications.\n",
    "    - Using a dashboard like Grafana for visual alerts.\n",
    "        - Note: Example assumes integration with a monitoring system\n",
    "        - Alert setup would involve creating a data source and alert rule in Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Using AI for Data Quality Monitoring\n",
    "**Steps**:\n",
    "1. Basic AI Models for Monitoring\n",
    "    - Train a simple anomaly detection model using Isolation Forest.\n",
    "    - Use a simple custom function based AI logic for outlier detection.\n",
    "    - Creating a monitoring function that utilizes a pre-trained machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (2.1.4)\n",
      "Requirement already satisfied: pandas-profiling in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (3.6.6)\n",
      "Requirement already satisfied: great-expectations in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (1.4.3)\n",
      "Requirement already satisfied: scikit-learn in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: ydata-profiling in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pandas-profiling) (4.16.1)\n",
      "Requirement already satisfied: altair<5.0.0,>=4.2.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (4.2.2)\n",
      "Requirement already satisfied: cryptography>=3.2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (44.0.3)\n",
      "Requirement already satisfied: jinja2>=3 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (4.23.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.7.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (3.26.1)\n",
      "Requirement already satisfied: mistune>=0.8.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (3.1.3)\n",
      "Requirement already satisfied: packaging in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (25.0)\n",
      "Requirement already satisfied: posthog<4,>3 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (3.25.0)\n",
      "Requirement already satisfied: pydantic>=1.10.7 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (2.11.4)\n",
      "Requirement already satisfied: pyparsing>=2.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (3.2.3)\n",
      "Requirement already satisfied: requests>=2.20 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (2.32.3)\n",
      "Requirement already satisfied: ruamel.yaml>=0.16 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (0.18.10)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (1.15.3)\n",
      "Requirement already satisfied: tqdm>=4.59.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (4.13.2)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from great-expectations) (5.3.1)\n",
      "Requirement already satisfied: entrypoints in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from altair<5.0.0,>=4.2.1->great-expectations) (0.4)\n",
      "Requirement already satisfied: toolz in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from altair<5.0.0,>=4.2.1->great-expectations) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from posthog<4,>3->great-expectations) (1.17.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from posthog<4,>3->great-expectations) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from posthog<4,>3->great-expectations) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from posthog<4,>3->great-expectations) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from requests>=2.20->great-expectations) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from requests>=2.20->great-expectations) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from requests>=2.20->great-expectations) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from requests>=2.20->great-expectations) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from cryptography>=3.2->great-expectations) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.2->great-expectations) (2.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jinja2>=3->great-expectations) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jsonschema>=2.5.1->great-expectations) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jsonschema>=2.5.1->great-expectations) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jsonschema>=2.5.1->great-expectations) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from jsonschema>=2.5.1->great-expectations) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pydantic>=1.10.7->great-expectations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pydantic>=1.10.7->great-expectations) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from pydantic>=1.10.7->great-expectations) (0.4.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ruamel.yaml>=0.16->great-expectations) (0.2.12)\n",
      "Requirement already satisfied: matplotlib<=3.10,>=3.5 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (3.10.0)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (6.0.2)\n",
      "Requirement already satisfied: visions<0.8.2,>=0.7.5 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling->pandas-profiling) (0.8.1)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (0.12.4)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (0.13.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (1.12)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (0.14.4)\n",
      "Requirement already satisfied: typeguard<5,>=3 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (4.4.2)\n",
      "Requirement already satisfied: imagehash==4.3.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.3 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (1.9.4)\n",
      "Requirement already satisfied: dacite>=1.8 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (1.9.2)\n",
      "Requirement already satisfied: numba<=0.61,>=0.56.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from ydata-profiling->pandas-profiling) (0.61.0)\n",
      "Requirement already satisfied: PyWavelets in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (1.8.0)\n",
      "Requirement already satisfied: pillow in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling->pandas-profiling) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling->pandas-profiling) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling->pandas-profiling) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling->pandas-profiling) (1.4.8)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from numba<=0.61,>=0.56.0->ydata-profiling->pandas-profiling) (0.44.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from statsmodels<1,>=0.13.2->ydata-profiling->pandas-profiling) (1.0.1)\n",
      "Requirement already satisfied: networkx>=2.4 in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling->pandas-profiling) (3.4.2)\n",
      "Requirement already satisfied: puremagic in /workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling->pandas-profiling) (1.29)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas pandas-profiling great-expectations scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticImportError",
     "evalue": "`BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.11/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/import-error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPydanticImportError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgx\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IsolationForest\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas_profiling/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m.. include:: ../../README.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompare_reports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compare\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontroller\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pandas_decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas_profiling/compare_reports.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional, Tuple, Union\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Correlation, Settings\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malerts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Alert\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprofile_report\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ProfileReport\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas_profiling/config.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, Union\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, BaseSettings, Field, PrivateAttr\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_merge_dictionaries\u001b[39m(dict1: \u001b[38;5;28mdict\u001b[39m, dict2: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Recursive merge dictionaries.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    :return: Merged dictionary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pydantic/__init__.py:426\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    424\u001b[0m dynamic_attr \u001b[38;5;241m=\u001b[39m _dynamic_imports\u001b[38;5;241m.\u001b[39mget(attr_name)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_getattr_migration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m package, module_name \u001b[38;5;241m=\u001b[39m dynamic_attr\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__module__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pydantic/_migration.py:296\u001b[0m, in \u001b[0;36mgetattr_migration.<locals>.wrapper\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m import_string(REDIRECT_TO_V1[import_path])\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpydantic:BaseSettings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://docs.pydantic.dev/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_short()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor more details.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    300\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m import_path \u001b[38;5;129;01min\u001b[39;00m REMOVED_IN_V2:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticImportError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` has been removed in V2.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mPydanticImportError\u001b[0m: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.11/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.11/u/import-error"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import great_expectations as gx\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging for alerts\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# --- Task 1: Automated Data Profiling ---\n",
    "print(\"\\n--- Task 1: Automated Data Profiling ---\")\n",
    "\n",
    "# Assuming you have a CSV file named 'your_data.csv' in the same directory\n",
    "try:\n",
    "    df_profile = pd.read_csv('your_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'your_data.csv' not found. Please create a sample CSV file for profiling.\")\n",
    "    df_profile = pd.DataFrame({'col1': [1, 2, 3], 'col2': ['a', 'b', 'c'], 'col3': [1.1, 2.2, 3.3]}) # Sample DataFrame\n",
    "\n",
    "# 1. Using Pandas-Profiling\n",
    "print(\"\\n1. Using Pandas-Profiling:\")\n",
    "profile = ProfileReport(df_profile, title=\"Pandas Profiling Report\", explorative=True, correlations=True)\n",
    "profile.to_file(\"data_profile.html\")\n",
    "print(\"Pandas Profiling report generated as 'data_profile.html'\")\n",
    "\n",
    "# Profile a specific subset of columns\n",
    "subset_profile = ProfileReport(df_profile[['col1', 'col3']], title=\"Subset Profile\", explorative=True)\n",
    "subset_profile.to_file(\"subset_profile.html\")\n",
    "print(\"Subset profile generated as 'subset_profile.html' for columns 'col1' and 'col3'\")\n",
    "\n",
    "# 2. Using Great Expectations\n",
    "print(\"\\n2. Using Great Expectations:\")\n",
    "try:\n",
    "    context = gx.DataContext.create()\n",
    "except Exception as e:\n",
    "    print(f\"Error creating DataContext: {e}\")\n",
    "    print(\"Please ensure you have initialized a Great Expectations project.\")\n",
    "    print(\"You can do this by running 'great_expectations init' in your terminal.\")\n",
    "    context = None\n",
    "\n",
    "if context:\n",
    "    datasource_name = \"pandas_source\"\n",
    "    data_connector_name = \"default_pandas_in_memory_data_connector\"\n",
    "    data_asset_name = \"profile_data\"\n",
    "\n",
    "    batch_request = {\n",
    "        \"datasource_name\": datasource_name,\n",
    "        \"data_connector_name\": data_connector_name,\n",
    "        \"data_asset_name\": data_asset_name,\n",
    "        \"batch_spec_passthrough\": {\"dataframe\": df_profile},\n",
    "    }\n",
    "\n",
    "    expectation_suite_name = \"data_quality_suite\"\n",
    "    try:\n",
    "        suite = context.get_expectation_suite(expectation_suite_name)\n",
    "        print(f\"Loaded existing Expectation Suite: {expectation_suite_name}\")\n",
    "    except gx.exceptions.ExpectationSuiteNotFoundError:\n",
    "        suite = context.create_expectation_suite(expectation_suite_name)\n",
    "        print(f\"Created a new Expectation Suite: {expectation_suite_name}\")\n",
    "\n",
    "    # Add multiple expectations to the suite\n",
    "    suite.expect_column_values_to_not_be_null(\"col1\")\n",
    "    suite.expect_column_values_to_be_in_set(\"col2\", [\"a\", \"b\", \"c\", \"d\"])\n",
    "    suite.expect_column_values_to_be_between(\"col3\", 1, 4)\n",
    "\n",
    "    context.save_expectation_suite(suite)\n",
    "\n",
    "    validator = context.get_validator(\n",
    "        batch_request=batch_request,\n",
    "        expectation_suite_name=expectation_suite_name,\n",
    "    )\n",
    "    print(\"\\nValidation Results:\")\n",
    "    validation_result = validator.validate()\n",
    "    print(validation_result)\n",
    "\n",
    "    if not validation_result[\"success\"]:\n",
    "        print(\"Data quality issues found based on Great Expectations!\")\n",
    "\n",
    "# --- Task 2: Real-time Monitoring of Data Quality ---\n",
    "print(\"\\n--- Task 2: Real-time Monitoring of Data Quality ---\")\n",
    "\n",
    "# Dummy function to simulate data arrival\n",
    "def fetch_real_time_data():\n",
    "    # In a real scenario, this would fetch data from a stream or source\n",
    "    time.sleep(2)\n",
    "    new_data = {'col1': [4], 'col2': ['e'], 'col3': [5.0]}\n",
    "    return pd.DataFrame(new_data)\n",
    "\n",
    "# Email configuration (replace with your actual details)\n",
    "SMTP_SERVER = 'your_smtp_server.com'\n",
    "SMTP_PORT = 587\n",
    "SMTP_USERNAME = 'your_email@example.com'\n",
    "SMTP_PASSWORD = 'your_email_password'\n",
    "SENDER_EMAIL = 'your_email@example.com'\n",
    "RECEIVER_EMAIL = 'recipient@example.com'\n",
    "\n",
    "def send_email_alert(subject, body):\n",
    "    try:\n",
    "        msg = MIMEText(body)\n",
    "        msg['Subject'] = subject\n",
    "        msg['From'] = SENDER_EMAIL\n",
    "        msg['To'] = RECEIVER_EMAIL\n",
    "\n",
    "        with smtplib.SMTP(SMTP_SERVER, SMTP_PORT) as server:\n",
    "            server.starttls()\n",
    "            server.login(SMTP_USERNAME, SMTP_PASSWORD)\n",
    "            server.sendmail(SENDER_EMAIL, [RECEIVER_EMAIL], msg.as_string())\n",
    "        logging.info(f\"Email alert sent: {subject}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error sending email: {e}\")\n",
    "\n",
    "def monitor_data_quality():\n",
    "    print(\"\\nStarting data quality monitoring...\")\n",
    "    for _ in range(3): # Simulate monitoring over a few intervals\n",
    "        new_df = fetch_real_time_data()\n",
    "        print(f\"\\nFetched new data:\\n{new_df}\")\n",
    "\n",
    "        if context:\n",
    "            batch_request = {\n",
    "                \"datasource_name\": datasource_name,\n",
    "                \"data_connector_name\": data_connector_name,\n",
    "                \"data_asset_name\": \"realtime_data\",\n",
    "                \"batch_spec_passthrough\": {\"dataframe\": new_df},\n",
    "            }\n",
    "            validator = context.get_validator(\n",
    "                batch_request=batch_request,\n",
    "                expectation_suite_name=expectation_suite_name,\n",
    "            )\n",
    "            validation_result = validator.validate()\n",
    "            print(\"Real-time Validation Results:\")\n",
    "            print(validation_result)\n",
    "\n",
    "            if not validation_result[\"success\"]:\n",
    "                logging.warning(\"Data quality check failed!\")\n",
    "                alert_subject = \"Data Quality Alert - Failed Expectations\"\n",
    "                alert_body = f\"Data at {datetime.now()} failed the following expectations:\\n{validation_result['results']}\"\n",
    "                send_email_alert(alert_subject, alert_body)\n",
    "        else:\n",
    "            logging.warning(\"Great Expectations context not initialized, skipping real-time validation.\")\n",
    "\n",
    "monitor_data_quality()\n",
    "\n",
    "# --- Task 3: Using AI for Data Quality Monitoring ---\n",
    "print(\"\\n--- Task 3: Using AI for Data Quality Monitoring ---\")\n",
    "\n",
    "# Assuming you have some numerical data for anomaly detection\n",
    "numerical_data = df_profile[['col1', 'col3']].dropna().values\n",
    "\n",
    "if numerical_data.shape[0] > 0:\n",
    "    # 1. Train a simple anomaly detection model using Isolation Forest\n",
    "    print(\"\\n1. Training Isolation Forest for anomaly detection:\")\n",
    "    model = IsolationForest(contamination='auto', random_state=42)\n",
    "    model.fit(numerical_data)\n",
    "\n",
    "    # Use a simple custom function based on AI logic for outlier detection (e.g., using the model's decision function)\n",
    "    def detect_anomalies(data, model, threshold=-0.1): # Adjust threshold as needed\n",
    "        scores = model.decision_function(data)\n",
    "        anomalies = data[scores < threshold]\n",
    "        return anomalies\n",
    "\n",
    "    # Detect anomalies in the original numerical data\n",
    "    anomalous_points = detect_anomalies(numerical_data, model)\n",
    "    print(\"\\nAnomalous points detected by Isolation Forest:\")\n",
    "    print(anomalous_points)\n",
    "\n",
    "    # Creating a monitoring function that utilizes a pre-trained machine learning model\n",
    "    def monitor_with_ai(new_numerical_data, model, threshold=-0.1):\n",
    "        anomalies = detect_anomalies(new_numerical_data, model, threshold)\n",
    "        if len(anomalies) > 0:\n",
    "            logging.warning(f\"AI-based anomaly detection found {len(anomalies)} potential issues: {anomalies}\")\n",
    "            alert_subject = \"AI-Based Data Quality Alert - Anomalies Detected\"\n",
    "            alert_body = f\"Potential data anomalies detected at {datetime.now()}:\\n{anomalies}\"\n",
    "            send_email_alert(alert_subject, alert_body)\n",
    "        else:\n",
    "            logging.info(\"AI-based monitoring: No anomalies detected.\")\n",
    "\n",
    "    # Simulate monitoring with AI on new numerical data\n",
    "    new_numerical_data = np.array([[6, 7.0], [1.5, 2.0], [10, 11.0]])\n",
    "    print(\"\\nMonitoring new numerical data with the AI model:\")\n",
    "    monitor_with_ai(new_numerical_data, model)\n",
    "\n",
    "else:\n",
    "    print(\"Not enough numerical data for anomaly detection.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

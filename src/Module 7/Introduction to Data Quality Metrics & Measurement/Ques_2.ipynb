{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Framework Implementation\n",
    "\n",
    "**Description**: Implement a simple data quality measurement framework using ISO 8000 principles to assess key dimensions in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assessing Completeness...\n",
      "  Completeness of 'ID': 100.00%\n",
      "  Completeness of 'Name': 83.33%\n",
      "  Completeness of 'Age': 100.00%\n",
      "  Completeness of 'City1': 100.00%\n",
      "  Completeness of 'City2': 100.00%\n",
      "\n",
      "Assessing Completeness...\n",
      "  Completeness of 'Name': 83.33%\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Income'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Income'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Assess Completeness\u001b[39;00m\n\u001b[1;32m    116\u001b[0m dq_framework\u001b[38;5;241m.\u001b[39massess_completeness()\n\u001b[0;32m--> 117\u001b[0m \u001b[43mdq_framework\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massess_completeness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIncome\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Assuming 'Income' was added\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Assess Accuracy\u001b[39;00m\n\u001b[1;32m    120\u001b[0m dq_framework\u001b[38;5;241m.\u001b[39massess_accuracy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, valid_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m100\u001b[39m))\n",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m, in \u001b[0;36mDataQualityFramework.assess_completeness\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m     17\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m---> 19\u001b[0m     total_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     20\u001b[0m     non_missing_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[col]\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m     21\u001b[0m     completeness \u001b[38;5;241m=\u001b[39m (non_missing_values \u001b[38;5;241m/\u001b[39m total_values) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total_values \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/workspaces/AI_DATA_ANALYSIS_/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Income'"
     ]
    }
   ],
   "source": [
    "# Write a conceptual framework described in Python pseudo-code:\n",
    "# DataQualityFramework Class\n",
    "\n",
    "class DataQualityFramework:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.quality_metrics = {}\n",
    "\n",
    "    def assess_completeness(self, columns=None):\n",
    "        \"\"\"\n",
    "        Measures the completeness of specified columns (or all columns).\n",
    "        Completeness = (Number of non-missing values / Total number of values) * 100\n",
    "        \"\"\"\n",
    "        print(\"\\nAssessing Completeness...\")\n",
    "        completeness_scores = {}\n",
    "        if columns is None:\n",
    "            columns = self.dataset.columns\n",
    "        for col in columns:\n",
    "            total_values = len(self.dataset[col])\n",
    "            non_missing_values = self.dataset[col].count()\n",
    "            completeness = (non_missing_values / total_values) * 100 if total_values > 0 else 0\n",
    "            completeness_scores[col] = completeness\n",
    "            print(f\"  Completeness of '{col}': {completeness:.2f}%\")\n",
    "        self.quality_metrics['completeness'] = completeness_scores\n",
    "\n",
    "    def assess_accuracy(self, column, expected_format=None, valid_range=None, custom_rule=None):\n",
    "        \"\"\"\n",
    "        Measures the accuracy of a specified column based on expected format, valid range, or a custom rule.\n",
    "        Accuracy (simplified) = (Number of valid values / Total number of values) * 100\n",
    "        \"\"\"\n",
    "        print(f\"\\nAssessing Accuracy for '{column}'...\")\n",
    "        valid_count = 0\n",
    "        total_values = len(self.dataset[column])\n",
    "        if total_values == 0:\n",
    "            accuracy = 0\n",
    "        else:\n",
    "            for value in self.dataset[column]:\n",
    "                is_valid = True\n",
    "                if expected_format and not isinstance(value, expected_format):\n",
    "                    is_valid = False\n",
    "                if valid_range and not (valid_range[0] <= value <= valid_range[1]):\n",
    "                    is_valid = False\n",
    "                if custom_rule and not custom_rule(value):\n",
    "                    is_valid = False\n",
    "                if is_valid and pd.notna(value): # Consider non-missing and valid\n",
    "                    valid_count += 1\n",
    "            accuracy = (valid_count / total_values) * 100\n",
    "        print(f\"  Accuracy of '{column}': {accuracy:.2f}%\")\n",
    "        if 'accuracy' not in self.quality_metrics:\n",
    "            self.quality_metrics['accuracy'] = {}\n",
    "        self.quality_metrics['accuracy'][column] = accuracy\n",
    "\n",
    "    def assess_consistency(self, column1, column2, consistency_rule):\n",
    "        \"\"\"\n",
    "        Measures the consistency between two specified columns based on a given rule.\n",
    "        Consistency (simplified) = (Number of consistent pairs / Total number of pairs) * 100\n",
    "        \"\"\"\n",
    "        print(f\"\\nAssessing Consistency between '{column1}' and '{column2}'...\")\n",
    "        consistent_count = 0\n",
    "        total_pairs = len(self.dataset)\n",
    "        if total_pairs == 0:\n",
    "            consistency = 0\n",
    "        else:\n",
    "            for index, row in self.dataset.iterrows():\n",
    "                value1 = row[column1]\n",
    "                value2 = row[column2]\n",
    "                if pd.notna(value1) and pd.notna(value2) and consistency_rule(value1, value2):\n",
    "                    consistent_count += 1\n",
    "            consistency = (consistent_count / total_pairs) * 100\n",
    "        print(f\"  Consistency between '{column1}' and '{column2}': {consistency:.2f}%\")\n",
    "        if 'consistency' not in self.quality_metrics:\n",
    "            self.quality_metrics['consistency'] = {}\n",
    "        self.quality_metrics['consistency'][(column1, column2)] = consistency\n",
    "\n",
    "    def assess_uniqueness(self, columns):\n",
    "        \"\"\"\n",
    "        Measures the uniqueness of records based on specified columns.\n",
    "        Uniqueness = (Number of unique records / Total number of records) * 100\n",
    "        \"\"\"\n",
    "        print(f\"\\nAssessing Uniqueness based on columns: {columns}...\")\n",
    "        total_records = len(self.dataset)\n",
    "        unique_records = self.dataset.duplicated(subset=columns, keep=False).sum() # Count all duplicates\n",
    "        uniqueness = ((total_records - unique_records) / total_records) * 100 if total_records > 0 else 0\n",
    "        print(f\"  Uniqueness based on {columns}: {uniqueness:.2f}%\")\n",
    "        self.quality_metrics['uniqueness'] = uniqueness\n",
    "\n",
    "    def get_quality_report(self):\n",
    "        \"\"\"\n",
    "        Returns a summary of the assessed data quality metrics.\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Data Quality Report ---\")\n",
    "        for metric, scores in self.quality_metrics.items():\n",
    "            print(f\"\\n{metric.capitalize()}:\")\n",
    "            if isinstance(scores, dict):\n",
    "                for item, score in scores.items():\n",
    "                    print(f\"  {item}: {score:.2f}%\")\n",
    "            else:\n",
    "                print(f\"  Overall: {scores:.2f}%\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample Dataset\n",
    "data = {'ID': [1, 2, 3, 4, 5, 1],\n",
    "        'Name': ['Alice', 'Bob', 'Charlie', 'David', np.nan, 'Alice'],\n",
    "        'Age': [25, 30, 120, 40, 28, 25],\n",
    "        'City1': ['Bangalore', 'Mumbai', 'Chennai', 'Bangalore', 'Delhi', 'Mumbai'],\n",
    "        'City2': ['Bangalore', 'Bombay', 'Chennai', 'Bangalore', 'Delhi', 'Mumbai']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize the Data Quality Framework\n",
    "dq_framework = DataQualityFramework(df)\n",
    "\n",
    "# Assess Completeness\n",
    "dq_framework.assess_completeness()\n",
    "dq_framework.assess_completeness(columns=['Name', 'Income']) # Assuming 'Income' was added\n",
    "\n",
    "# Assess Accuracy\n",
    "dq_framework.assess_accuracy('Age', valid_range=(0, 100))\n",
    "dq_framework.assess_accuracy('Name', expected_format=str)\n",
    "\n",
    "# Assess Consistency\n",
    "def check_city_consistency(city1, city2):\n",
    "    # Simple rule: ignore case and 'bay'/'bai' variations\n",
    "    c1 = str(city1).lower().replace('bay', 'bai')\n",
    "    c2 = str(city2).lower().replace('bay', 'bai')\n",
    "    return c1 == c2\n",
    "dq_framework.assess_consistency('City1', 'City2', check_city_consistency)\n",
    "\n",
    "# Assess Uniqueness\n",
    "dq_framework.assess_uniqueness(['ID'])\n",
    "dq_framework.assess_uniqueness(['Name', 'Age'])\n",
    "\n",
    "# Get the Quality Report\n",
    "dq_framework.get_quality_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using NLP for Text Data Quality\n",
    "**Objective**: Enhance text data quality using NLP techniques.\n",
    "\n",
    "**Task**: Removing Stopwords\n",
    "\n",
    "**Steps**:\n",
    "1. Data Set: Use a dataset of text product descriptions.\n",
    "2. Stopword Removal: Utilize an NLP library (e.g., NLTK) to remove stopwords from the\n",
    "descriptions.\n",
    "3. Assess Impact: Examine the effectiveness by analyzing word frequency before and after\n",
    "removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m word_tokenize\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if you haven't already\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "try:\n",
    "    word_tokenize(\"example\")\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "# Step 1: Use a dataset of text product descriptions.\n",
    "# Generate sample product descriptions\n",
    "data = {\n",
    "    'ProductDescription': [\n",
    "        \"This is a fantastic new smartphone with a large screen and amazing camera features.\",\n",
    "        \"The comfortable and stylish running shoes are perfect for your daily workout routine.\",\n",
    "        \"A high-quality leather wallet that is both durable and has plenty of space for cards and cash.\",\n",
    "        \"This set of colorful and vibrant art markers is ideal for artists of all skill levels.\",\n",
    "        \"The lightweight and portable Bluetooth speaker delivers powerful sound for any occasion.\"\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame with Product Descriptions:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Stopword Removal: Utilize an NLP library (e.g., NLTK) to remove stopwords from the descriptions.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text.lower())\n",
    "    filtered_words = [word for word in word_tokens if word not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df['Description_NoStopwords'] = df['ProductDescription'].apply(remove_stopwords)\n",
    "\n",
    "print(\"\\nDataFrame after Stopword Removal:\")\n",
    "print(df)\n",
    "\n",
    "# Step 3: Assess Impact: Examine the effectiveness by analyzing word frequency before and after removal.\n",
    "\n",
    "# Analyze word frequency before stopword removal\n",
    "all_words_original = []\n",
    "for desc in df['ProductDescription']:\n",
    "    word_tokens = word_tokenize(desc.lower())\n",
    "    all_words_original.extend(word_tokens)\n",
    "\n",
    "word_frequency_original = Counter(all_words_original)\n",
    "print(\"\\nTop 20 Most Frequent Words (Original):\")\n",
    "print(word_frequency_original.most_common(20))\n",
    "\n",
    "# Analyze word frequency after stopword removal\n",
    "all_words_nostopwords = []\n",
    "for desc in df['Description_NoStopwords']:\n",
    "    word_tokens = word_tokenize(desc.lower())\n",
    "    all_words_nostopwords.extend(word_tokens)\n",
    "\n",
    "word_frequency_nostopwords = Counter(all_words_nostopwords)\n",
    "print(\"\\nTop 20 Most Frequent Words (After Stopword Removal):\")\n",
    "print(word_frequency_nostopwords.most_common(20))\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"Notice how common English words like 'is', 'a', 'with', 'and', 'that', 'for', 'of', 'are', 'your', 'both' appear frequently in the original word counts.\")\n",
    "print(\"After removing stopwords, the most frequent words are more content-related, such as 'smartphone', 'screen', 'camera', 'features', 'comfortable', 'running', 'shoes', 'workout', etc.\")\n",
    "print(\"This demonstrates how stopword removal can help to focus on the more important words in the text for analysis.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Data Errors Examples\n",
    "\n",
    "# 1. Missing Data:\n",
    "# Task 1: Review a dataset where some customer emails are missing. Identify how\n",
    "# many records are incomplete.\n",
    "# Task 2: Examine a sales dataset with missing transaction dates and determine the\n",
    "# percentage of missing data.\n",
    "# Task 3: Identify missing department information in an employee registry.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Duplicate Data:\n",
    "# Task 1: Analyze a customer dataset with duplicate entries and count the number of\n",
    "# duplicates.\n",
    "# Task 2: Review supplier data and identify any repeated supplier names.\n",
    "# Task 3: Examine a product inventory list for duplicates in product IDs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Inconsistent Formatting:\n",
    "# Task 1: Spot inconsistencies in date formats (e.g., DD/MM/YYYY vs. MM/DD/YYYY)\n",
    "# in a dataset.\n",
    "# Task 2: Identify phone numbers with varying formats in a contact list.\n",
    "# Task 3: Review address data for discrepancies in state abbreviations (e.g., CA vs.\n",
    "# Calif.).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. Data Drift:\n",
    "# Task 1: Compare monthly revenues over six months to identify data drift.\n",
    "# Task 2: Analyze user engagement metrics from a web application over different\n",
    "# quarters.\n",
    "# Task 3: Review a stock price dataset to detect any anomalies over a year.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Missing Data ---\n",
      "Task 1: Number of records with missing emails: 2\n",
      "Task 2: Number of missing transaction dates: 2\n",
      "        Percentage of missing transaction dates: 33.33%\n",
      "Task 3: Number of employees with missing department information: 1\n",
      "\n",
      "--- 2. Duplicate Data ---\n",
      "Task 1: Number of duplicate customer entries: 2\n",
      "Task 2: Number of repeated supplier names: 2\n",
      "Task 3: Number of duplicate product IDs: 2\n",
      "\n",
      "--- 3. Inconsistent Formatting ---\n",
      "Task 1: Inconsistent date formats in the 'EventDate' column:\n",
      "0    15/01/2024\n",
      "1    02-20-2024\n",
      "2    2024-03-10\n",
      "3    04/25/2024\n",
      "4    2024-05-01\n",
      "Name: EventDate, dtype: object\n",
      "Task 2: Phone numbers with varying formats in the 'PhoneNumber' column:\n",
      "0       123-456-7890\n",
      "1     (123) 456 7890\n",
      "2         1234567890\n",
      "3    +1-123-456-7890\n",
      "4       123.456.7890\n",
      "Name: PhoneNumber, dtype: object\n",
      "Task 3: Inconsistent state abbreviations: ['CA' 'Calif.' 'NY']\n",
      "\n",
      "--- 4. Data Drift ---\n",
      "Task 1: Monthly Revenues (Q1):\n",
      "  Month  Revenue\n",
      "0   Jan    10000\n",
      "1   Feb    11000\n",
      "2   Mar    12500\n",
      "\n",
      "        Monthly Revenues (Q2):\n",
      "  Month  Revenue\n",
      "0   Apr    13000\n",
      "1   May    11500\n",
      "2   Jun    14000\n",
      "\n",
      "Task 2: User Engagement Metrics (Q1):\n",
      "               Metric  Value\n",
      "0    Avg Session Time   25.5\n",
      "1  Daily Active Users  500.0\n",
      "\n",
      "        User Engagement Metrics (Q2):\n",
      "               Metric  Value\n",
      "0    Avg Session Time   28.1\n",
      "1  Daily Active Users  520.0\n",
      "\n",
      "Task 3: Stock Price Data:\n",
      "        Date   Price\n",
      "0 2024-01-01  150.10\n",
      "1 2024-01-02  150.50\n",
      "2 2024-01-03  150.25\n",
      "3 2024-01-04  150.75\n",
      "4 2024-07-15  165.00\n",
      "5 2024-07-16  165.20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Missing Data ---\n",
    "\n",
    "print(\"\\n--- 1. Missing Data ---\")\n",
    "\n",
    "# Task 1: Missing Customer Emails\n",
    "customer_data = {'CustomerID': [1, 2, 3, 4, 5],\n",
    "                 'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "                 'Email': ['alice@example.com', np.nan, 'charlie@example.com', np.nan, 'eve@example.com']}\n",
    "customer_df = pd.DataFrame(customer_data)\n",
    "incomplete_email_records = customer_df['Email'].isnull().sum()\n",
    "print(f\"Task 1: Number of records with missing emails: {incomplete_email_records}\")\n",
    "\n",
    "# Task 2: Missing Transaction Dates\n",
    "sales_data = {'TransactionID': [101, 102, 103, 104, 105, 106],\n",
    "              'ProductID': [1, 2, 1, 3, 2, 4],\n",
    "              'TransactionDate': ['2024-01-15', np.nan, '2024-01-20', '2024-02-01', np.nan, '2024-02-10']}\n",
    "sales_df = pd.DataFrame(sales_data)\n",
    "missing_date_count = sales_df['TransactionDate'].isnull().sum()\n",
    "total_records = len(sales_df)\n",
    "missing_date_percentage = (missing_date_count / total_records) * 100\n",
    "print(f\"Task 2: Number of missing transaction dates: {missing_date_count}\")\n",
    "print(f\"        Percentage of missing transaction dates: {missing_date_percentage:.2f}%\")\n",
    "\n",
    "# Task 3: Missing Department Information\n",
    "employee_data = {'EmployeeID': [1001, 1002, 1003, 1004],\n",
    "                 'Name': ['John', 'Jane', 'Peter', 'Mary'],\n",
    "                 'Department': ['Sales', np.nan, 'Marketing', 'Sales']}\n",
    "employee_df = pd.DataFrame(employee_data)\n",
    "missing_dept_count = employee_df['Department'].isnull().sum()\n",
    "print(f\"Task 3: Number of employees with missing department information: {missing_dept_count}\")\n",
    "\n",
    "# --- 2. Duplicate Data ---\n",
    "\n",
    "print(\"\\n--- 2. Duplicate Data ---\")\n",
    "\n",
    "# Task 1: Duplicate Customer Entries\n",
    "customer_data_duplicates = {'CustomerID': [1, 2, 3, 1, 4, 2],\n",
    "                             'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'David', 'Bob'],\n",
    "                             'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'alice@example.com', 'david@example.com', 'bob@example.com']}\n",
    "customer_duplicates_df = pd.DataFrame(customer_data_duplicates)\n",
    "duplicate_customer_count = customer_duplicates_df.duplicated().sum()\n",
    "print(f\"Task 1: Number of duplicate customer entries: {duplicate_customer_count}\")\n",
    "\n",
    "# Task 2: Repeated Supplier Names\n",
    "supplier_data = {'SupplierID': [1, 2, 3, 4, 5, 3],\n",
    "                 'SupplierName': ['Acme Corp', 'Beta Inc', 'Gamma Ltd', 'Delta Co', 'Epsilon Group', 'Gamma Ltd'],\n",
    "                 'ContactPerson': ['John Smith', 'Jane Doe', 'Peter Jones', 'Mary Brown', 'David Lee', 'Peter Jones']}\n",
    "supplier_df = pd.DataFrame(supplier_data)\n",
    "repeated_supplier_names = supplier_df['SupplierName'].duplicated(keep=False).sum()\n",
    "print(f\"Task 2: Number of repeated supplier names: {repeated_supplier_names}\")\n",
    "\n",
    "# Task 3: Duplicate Product IDs\n",
    "inventory_data = {'ProductID': [101, 102, 103, 101, 104, 105],\n",
    "                  'ProductName': ['Laptop', 'Mouse', 'Keyboard', 'Laptop', 'Monitor', 'Webcam'],\n",
    "                  'Price': [1200, 25, 75, 1200, 300, 50]}\n",
    "inventory_df = pd.DataFrame(inventory_data)\n",
    "duplicate_product_ids = inventory_df['ProductID'].duplicated(keep=False).sum()\n",
    "print(f\"Task 3: Number of duplicate product IDs: {duplicate_product_ids}\")\n",
    "\n",
    "# --- 3. Inconsistent Formatting ---\n",
    "\n",
    "print(\"\\n--- 3. Inconsistent Formatting ---\")\n",
    "\n",
    "# Task 1: Inconsistent Date Formats\n",
    "date_data = {'RecordID': [1, 2, 3, 4, 5],\n",
    "             'EventDate': ['15/01/2024', '02-20-2024', '2024-03-10', '04/25/2024', '2024-05-01']}\n",
    "date_df = pd.DataFrame(date_data)\n",
    "print(\"Task 1: Inconsistent date formats in the 'EventDate' column:\")\n",
    "print(date_df['EventDate'])\n",
    "# Identifying and standardizing these would require more complex logic\n",
    "# potentially involving trying different parsing formats.\n",
    "\n",
    "# Task 2: Varying Phone Number Formats\n",
    "phone_data = {'ContactID': [1, 2, 3, 4, 5],\n",
    "              'PhoneNumber': ['123-456-7890', '(123) 456 7890', '1234567890', '+1-123-456-7890', '123.456.7890']}\n",
    "phone_df = pd.DataFrame(phone_data)\n",
    "print(\"Task 2: Phone numbers with varying formats in the 'PhoneNumber' column:\")\n",
    "print(phone_df['PhoneNumber'])\n",
    "# Standardizing these often involves removing non-numeric characters and then applying a consistent format.\n",
    "\n",
    "# Task 3: Discrepancies in State Abbreviations\n",
    "address_data = {'AddressID': [1, 2, 3, 4, 5],\n",
    "                'City': ['Los Angeles', 'Sacramento', 'New York', 'San Diego', 'Oakland'],\n",
    "                'State': ['CA', 'Calif.', 'NY', 'CA', 'CA']}\n",
    "address_df = pd.DataFrame(address_data)\n",
    "inconsistent_states = address_df['State'].unique()\n",
    "print(f\"Task 3: Inconsistent state abbreviations: {inconsistent_states}\")\n",
    "# Standardizing these would involve mapping different abbreviations to a standard form.\n",
    "\n",
    "# --- 4. Data Drift ---\n",
    "\n",
    "print(\"\\n--- 4. Data Drift ---\")\n",
    "\n",
    "# Task 1: Compare Monthly Revenues\n",
    "revenue_data_q1 = {'Month': ['Jan', 'Feb', 'Mar'], 'Revenue': [10000, 11000, 12500]}\n",
    "revenue_data_q2 = {'Month': ['Apr', 'May', 'Jun'], 'Revenue': [13000, 11500, 14000]}\n",
    "revenue_df_q1 = pd.DataFrame(revenue_data_q1)\n",
    "revenue_df_q2 = pd.DataFrame(revenue_data_q2)\n",
    "\n",
    "print(\"Task 1: Monthly Revenues (Q1):\")\n",
    "print(revenue_df_q1)\n",
    "print(\"\\n        Monthly Revenues (Q2):\")\n",
    "print(revenue_df_q2)\n",
    "# To detect drift, you might visualize this data (e.g., line plots) or use statistical tests\n",
    "# if you have more data points and want to assess significant changes in distribution.\n",
    "\n",
    "# Task 2: User Engagement Metrics Over Quarters\n",
    "engagement_q1 = {'Metric': ['Avg Session Time', 'Daily Active Users'], 'Value': [25.5, 500]}\n",
    "engagement_q2 = {'Metric': ['Avg Session Time', 'Daily Active Users'], 'Value': [28.1, 520]}\n",
    "engagement_df_q1 = pd.DataFrame(engagement_q1)\n",
    "engagement_df_q2 = pd.DataFrame(engagement_q2)\n",
    "\n",
    "print(\"\\nTask 2: User Engagement Metrics (Q1):\")\n",
    "print(engagement_df_q1)\n",
    "print(\"\\n        User Engagement Metrics (Q2):\")\n",
    "print(engagement_df_q2)\n",
    "# Similar to revenue, visualizing trends over time is a common way to identify drift in metrics.\n",
    "\n",
    "# Task 3: Stock Price Anomalies\n",
    "stock_data = {'Date': pd.to_datetime(['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04', '2024-07-15', '2024-07-16']),\n",
    "              'Price': [150.10, 150.50, 150.25, 150.75, 165.00, 165.20]}\n",
    "stock_df = pd.DataFrame(stock_data)\n",
    "\n",
    "print(\"\\nTask 3: Stock Price Data:\")\n",
    "print(stock_df)\n",
    "# Detecting anomalies often involves visualizing the data (e.g., line plot) and potentially using\n",
    "# statistical methods or machine learning models to identify unusual deviations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
